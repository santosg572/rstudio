---
title: "q3"
---

Computational_Physics_Philipp_C03

# Chapter 3 Numerical Differentiation

For more complex problems analytical derivatives are not always available and have to be approximated by numerical methods. If numerical precision plays a role a simple difference quotient is not sufficient and more accurate methods are necessary

which will be discussed in this chapter.

## 3.1 Simple Forward Difference

The simplest method approximates the derivative by the quotient of finite differences

$$
\frac{df}{dx} ≈ \frac{\Delta f}{\Delta x} = \frac{f (x + h) − f (x)}{h}
$$

The truncation error can be estimated from the Taylor series expansion

$$
\frac{f(x + h) − f(x)}{h} = \frac{f(x) + hf′(x) + \frac{h}{2} f''(x) +...=f(c)}{h} \\
= f′(x) + \frac{h}{2} f′′(x) + · · · .
$$

The error order is O(h). The step width should not be too small to avoid rounding errors. Error analysis gives

$$
\tilde{\Delta f} = fl-(f(x + h)(1 + \varepsilon_1 ε1), f(x)(1 + ε_2)) \\
= (\Delta f + f(x + h)ε_1 − f(x)ε_2)(1 + ε_3) \\
= \Delta f + \Delta f ε_3 + f(x + h)ε_1 − f(x)ε_2 + · · · ,
$$

$$
fl÷(\tilde{\Delta f}, h(1 + ε_4)) = \frac{\Delta f + \Delta f ε_3 + f(x + h)ε_1 − f (x)ε_2}{h(1 + ε_4)} (1 + ε5)
= \frac{\Delta f}{h} (1 + ε_5 − ε_4 + ε_3)+ \frac{f(x + h)}{h} ε_1 − \frac{f(x)}{h} ε_2
$$

The errors are uncorrelated and the relative error of the result can be estimated by

$$
\frac{∣\frac{\tilde{\Delta f}}{\Delta x}- \frac{\Delta f}{\Delta x}∣}{\frac{\Delta f}{\Delta x}} \leq 3 \varepsilon_M + ∣\frac{f(x)}{\frac{\Delta f}{\Delta x}}∣ 2 \frac{\varepsilon_M}{h}
$$

Numerical extinction produces large relative errors for small step width \$h\$. The optimal value of \$h\$ gives comparable errors from rounding and truncation. It can be found from

$$
\frac{h}{2} \|f′′(x)\| = \|f(x)\| \frac{2ε_M}{h}
$$

Assuming that the magnitude of the function and the derivative are comparable, we have the rule of thumb

$$
h_0 = \sqrt{ε_M} ≈ 10^{−8}
$$

(double precision). The corresponding relative error is of the same order.

## 3.2 Symmetrical Difference Quotient

Accuracy is much higher if a symmetrical difference quotient is used (Fig. 3.1):

$$
\frac{\Delta f}{\Delta x} = \frac{f(x + \frac{h}{2}) − f(x − \frac{h}{2} )}{h} \\
= \frac{f(x) + \frac{h}{2} f′(x) + \frac{h^2}{8} f′′(x) + ... - (f(x) − \frac{h}{2} f′(x) + \frac{h^2}{8} f'′(x) +...)}{h} = f′(x) + \frac{h^2}{24} f′′′(x) + ...
$$

The error order is \$O(h^2)\$. The optimal step width is estimated from

$$
\frac{h^2}{24} \| f′′′(x)\| = \| f(x)\|\frac{2ε_M}{h}
$$

again with the assumption that function and derivatives are of similar magnitude as

$$
h_0 = \sqrt[3]{48 \varepsilon_M} ≈ 10^{−5}.
$$

The relative error has to be expected in the order of \$\frac{h^2_0}{24} \approx 10^{-11}\$.

## 3.3 Extrapolation Methods

The Taylor series of the symmetric difference quotient contains only even powers of \$h\$:

$$
D(h) = \frac{f(x + h) − f(x − h)}{2h} = f′(x) + \frac{h^2}{3!} f′′′(x) + \frac{h^4}{5!} f^{(5)}(x) +...
$$

The extrapolation method [8] uses a series of step widths, e.g.,

$$
h_{i+1} = \frac{h_i}{2}
$$

and calculates an estimate of D(0) by polynomial interpolation. Consider

\$D_0 = D(h_0)\$ and \$D_1 = D(\frac{h_0}{2}\$). The polynomial of degree 1 (with respect to \$h^2\$) \$p(h) = a + bh^2\$ can be found by the Lagrange method:

$$
p(h) = D_0 \frac{h^2 - \frac{h^2_0}{4}}{h^2_0 - \frac{h^2_0}{4}} + D_1 \frac{h^2 - h^2_0}{\frac{h^2_0}{4} - \frac{h^2_0}{4}}
$$

Extrapolation for h = 0 gives

$$
p(0) = − \frac{1}{3} D_0 + \frac{4}{3} D_1
$$

Taylor series expansion shows

$$
p(0) = − \frac{1}{3}(f′(x) + \frac{h^2_0}{3!} f′′′(x) + \frac{h^4_0}{5!} f^{(5)}(x) + ...) \\
+\frac{4}{3}(f′(x) + \frac{h^2_0}{4·3!} f′′′(x) + \frac{h^4_0}{16·5!} f^{(5)} (x) + ... ) \\
= f′(x) − \frac{1}{4} \frac{h^4_0}{5!} f^{(5)} (x) + · · ·
$$

that the error order is \$O(h^4_0)\$. For three step widths \$h_0 = 2h_1 = 4h_2\$ we obtain the polynomial of second order (in \$h^2\$ ) (Fig. 3.2)

$$
p(h) = D_0 \frac{(h^2 − \frac{h^2_0}{4} )(h^2 − \frac{h^2_0}{16})}{(h^2_0 − \frac{h^2_0}{4})(h^2_0 − \frac{h^2_0}{16})} +
D_1 \frac{(h^2 − h^2_0)(h^2 − \frac{h^2_0}{16})}{(\frac{h^2_0}{4} − h^2_0)(\frac{h^2_0}{4} − \frac{h^2_0}{16})} +
D_2 \frac{(h^2 − h^2_0)(h^2 − \frac{h^2_0}{4})}{(\frac{h^2_0}{16} − h^2_0)(\frac{h^2_0}{16} − \frac{h^2_0}{4})}
$$

and the improved expression

$$
p(0) = D_0 \frac{\frac{1}{64}}{\frac{3}{4} \cdot \frac{15}{16} } +
D_1 \frac{\frac{1}{16}}{- \frac{3}{4} \cdot \frac{3}{16} } +
D_2 \frac{\frac{1}{4}}{-\frac{15}{16} \cdot -\frac{3}{16} } = \\
= \frac{1}{45} D_0 - \frac{4}{9}D_1 + \frac{64}{45} D_2 = f'(x) + O(h^6_0)
$$

Often used is the following series of step widths:

$$
h^2_i = \frac{h^2_0}{2^i}
$$

. (3.18)

The Neville method

$$
P_{i...k}(h^2) = \frac{(h^2 - \frac{h^2_0}{2^i})P_{i+1, ..., k}(h^2) - (h^2 - \frac{h^2_0}{2^k}) P_{i,..., k-1}(h^2)}{\frac{h^2_0}{2^k} - \frac{h^2_0}{2^i}}
$$

gives for h = 0

$$
P_{i...k} = \frac{P_{i...k−1} − 2^{k−i}P_{i+1...k}}{1 − 2^{k−i}}
$$

(3.20)

which can be written as

$$
P_{i...k} = P_{i+1...k} + \frac{P_{i...k−1} − P_{i+1...k}}{1 − 2^{k−i}}
$$

(3.21)

and can be calculated according to the following scheme:

$$
P_0 = D(h^2) P_{01} P_{012} P_{0123} \\
P_1 = D(\frac{h^2}{2}) P_{12} P_{123} \\
P_2 = D(\frac{h^2}{4}) P_{23}
\\
... ... ... . . .
$$

. (3.22)

Here the values of the polynomials are arranged in matrix form

$$
P_{i···k} = T_{i,k−i} = T_{i, j}
$$

(3.23)

with the recursion formula

$$
T_{i, j} = T_{i+1, j−1} + \frac{T_{i, j−1} − T_{i+1, j}}{1 − 2^j}
$$

. (3.24)

## 3.4 Higher Derivatives

Difference quotients for higher derivatives can be obtained systematically using

polynomial interpolation. Consider equidistant points

$$
x_n = x_0 + nh = ..., x_0 − 2h, x0 − h, x_0, x_0 + h, x_0 + 2h, ...
$$

. . . . (3.25)

From the second-order polynomial

$$
p(x) = y_{−1}\frac{(x−x_0)(x−x_1)}{(x_{−1}−x_0)(x_{−1}−x_1)} + y_0 \frac{(x−x_{−1})(x−x_1)}{(x_0−x_{−1})(x_0−x_1)}\\
+y_1 \frac{(x−x_{−1})(x−x_0)}
{(x_1−x_{−1})(x_1−x_0)}= \\
= y_{−1} \frac{(x−x_0)(x−x_1)}{2h^2} + y_0 \frac{(x − x_{−1})(x − x_1)}{−h^2}
\\
+y_1 \frac{(x − x_{−1})(x − x_0)}{2h^2}
$$

(3.26)

we calculate the derivatives

$$
p′(x) = y_{−1} \frac{2x − x_0 − x_1}{2h^2} + y_0 \frac{2x − x_{−1} − x_1}{−h^2} + y_1 \frac{2x − x_{−1} − x_0}{2h^2}
$$

, (3.27)

$$
p′′(x) = \frac{y_{−1}}{h^2} − 2 \frac{y_0}{h^2} + \frac{y_1}{h^2}
$$

, (3.28)

which are evaluated at \$x_0\$:

$$
f′(x_0) \approx p′(x_0) = -\frac{1}{2h}y_{−1}+\frac{1}{2h}y_1=\frac{f(x_0+h)−f(x_0−h)}{2h}
$$

, (3.29)

$$
f′′(x_0) ≈ p′′(x_0) = \frac{f(x_0 − h) − 2f (x_0) + f (x_0 + h)}{h^2}
$$

. (3.30)

Higher order polynomials can be evaluated with an algebra program. For five sample

points

$$
x_0 − 2h, x_0 − h, x0, x_0 + h, x_0 + 2h,
$$

we find

$$
f′(x_0) ≈ \frac{f(x_0 − 2h) − 8f(x_0 − h) + 8f(x_0 + h) − f(x_0 + 2h)}{12h}
$$

, (3.31)

$$
f′′(x_0) ≈ \frac{− f(x_0 − 2h) + 16 f (x_0 − h) − 30 f(x_0) + 16 f(x_0 + h) − f (x_0 + 2h)}{12h^2}
$$

,

(3.32)

$$
f′′′(x_0) ≈ \frac{− f (x_0 − 2h) + 2 f (x_0 − h) − 2 f(x_0 + h) + f(x_0 + 2h)}{2h^3}
$$

, (3.33)

$$
f^{(4)}(x_0) ≈ \frac{f(x_0 − 2h) − 4f (x_0 − h) + 6 f(x_0 + h) − 4 f(x_0 + h) + f(x_0 + 2h)}{h^4}
$$

.

(3.34)

## 3.5 More Dimensions

Consider polynomials of more than one variable. In two dimensions we use the

Lagrange polynomials

$$
L_{i,j}(x,y) = \prod _{k \neq i} \frac{(x - x_k)}{x_i - x_k} \prod _{j \neq l} \frac{y - y_l}{y_j - y_l}
$$

The interpolating polynomial is

$$
p(x, y) = ∑_{i, j}f_{i, j} L_{i, j} (x, y)
$$

. (3.36)

For the nine samples points

$$
(x_{−1}, y_1) (x_0, y_1) (x_1, y_1) \\
(x_{−1}, y_0) (x_0, y_0) (x_1, y_0) \\
(x_{−1}, y_{−1}) (x_0, y_{−1}) (x_1, y_{−1})
$$

(3.37)

we obtain the polynomial

$$
p(x, y) = f_{−1,−1} \frac{
(x − x_0)(x − x_1)(y − y_0)(y − y_1)}{
(x_{−1} − x_0)(x_{−1} − x_1)(y_{−1} − y_0)(y_{−1}) − y_1)} + · · ·
$$

, (3.38)

which gives an approximation to the gradient

$$
\triangledown f(x_0, y_0) \approx \triangledown p(x_0, y_0) = \begin{pmatrix}
\frac{f(x_0+h,y_0)− f (x_0−h,y_0)}{2h} \\
\frac{f(x_0,y_0+h)− f (x_0,y0−h)}{2h}
\end{pmatrix}
$$

(3.39)

and the Laplace operator

$$
∇^2 f(x_0, y_0) ≈ ∇^2 p(x_0, y_0)
= \frac{1}{h^2} ( f(x_0, y_0 + h) + f (x_0, y_0 − h) + f (x_0, y_0 + h) + f (x_0, y_0 − h) − 4 f (x_0, y_0))
$$

.

(3.40)

## Problems

\*\*Problem 3.1\*\* Numerical Differentiation

In this computer experiment we calculate the derivative of \$f(x) = \sin(x)\$ numerically with

\(a\) the single-sided difference quotient

$$
\frac{df}{dx} ≈ \frac{f(x + h) − f(x)}{h}
$$

\(b\) the symmetrical difference quotient

$$
\frac{df}{dx} ≈ D_h f(x) = \frac{f(x + h) − f (x − h)}{2h}
$$

\(c\) higher order approximations which can be derived using the extrapolation

method

$$
− \frac{1}{3} D_h f(x) + \frac{4}{3} D_{h/2} f(x) \\
\frac{1}{45} D_h f(x) − \frac{4}{9} D_{h/2} f(x) + \frac{64}{45} D_{h/4} f (x)
$$

The error of the numerical approximation is shown on a log--log plot as a function

of the step width h.
