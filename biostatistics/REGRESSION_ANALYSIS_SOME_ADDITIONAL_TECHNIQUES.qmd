---
title: "REGRESSION_ANALYSIS_SOME_ADDITIONAL_TECHNIQUES"
---

1.  Introduction

2.  Qualitative Independent Variables

3.  Variable Selection Procedures

4.  Logistic Regression

5.  Summary

    Review Questions and Exercises References 590

CHAPTER REGRESSION ANALYSIS: SOME ADDITIONAL TECHNIQUES

### CHAPTER OVERVIEW 

This chapter discusses some additional tools and concepts that are useful in regression analysis. The presentation includes expansions of the basic ideas and techniques of regression analysis that were introduced in Chapters 9 and 10.

### TOPICS 

11.1 INTRODUCTION

11.2 QUALITATIVE INDEPENDENT VARIABLES 11.3 VARIABLE SELECTION PROCEDURES 11.4 LOGISTIC REGRESSION

11.5 SUMMARY

### LEARNING OUTCOMES 

After studying this chapter, the student will

1.  understand how to include qualitative variables in a regression analysis.

2.  understand how to use automated variable selection procedures to develop regression models.

3.  be able to perform logistic regression for dichotomous and polytomous dependent variables.

    ### 11.1 INTRODUCTION 

    The basic concepts and methodology of regression analysis are covered in Chapters 9 and 10. In Chapter 9 we discuss the situation in which the objective is to obtain an equation that can be used to make predictions and estimates about some dependent variable from knowledge of some other single variable that we call the independent, predictor, or explanatory variable. In Chapter 10 the ideas and techniques learned in Chapter 9 are expanded to cover the situation in which it is believed that the inclusion of information on two or more independent variables will yield a better equation for use in making predictions and estimations. Regression analysis is a complex and pow- erful statistical tool that is widely employed in health sciences research. To do the sub- ject justice requires more space than is available in an introductory statistics textbook. However, for the benefit of those who wish additional coverage of regression analysis, we present in this chapter some additional topics that should prove helpful to the stu- dent and practitioner of statistics.

    **Regression Assumptions Revisited** As we learned in Chapters 9 and 10, there are several assumptions underlying the appropriate use of regression procedures. Often there are certain measurements that strongly influence the shape of a distribution or impact the magnitude of the variance of a measured variable. Other times, certain independent variables that are being used to develop a model are highly correlated, lead- ing to the development of a model that may not be unique or correct.

    **Non-Normal Data** Many times the data that are used to build a regression model are not normally distributed. One may wish to explore the possibility that some of the observed data points are outliers or that they disproportionately affect the distribution of the data. Such an investigation may be accomplished informally by constructing a scatter plot and looking for observations that do not seem to fit with the others. Alternatively, many computer packages produce formal tests to evaluate potential outlying observations in either the dependent variable or the independent variables. It is always up to the researcher, however, to justify which observations are to be removed from the data set prior to analysis.

    Often one may wish to attempt a transformation of the data. Mathematical trans- formations are useful because they do not affect the underlying relationships among variables. Since hypothesis tests for the regression coefficients are based on normal dis- tribution statistics, data transformations can sometimes normalize the data to the extent necessary to perform such tests. Simple transformations, such as taking the square root of measurements or taking the logarithm of measurements, are quite common.

    **EXAMPLE 11.1.1**

    Researchers were interested in blood concentrations of delta-9-tetrahydrocannabinol ()-9-THC), the active psychotropic component in marijuana, from 25 research subjects. These data are presented in Table 11.1.1, as are these same data after using a log10 trans- formation.11.1 INTRODUCTION 537 TABLE 11.1.1 Data from a Random Sample of 25 Research Subjects Tested for ≤ -9-THC, Example 11.1.1 Case No. Concentration (M g/ml)Log10 Concentration (M g/ml) 1 2 3 4.30 2.75 2.27 2.37!.52 .44 .36 .37 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 241.12 .60 .61 .89 .33 .85 2.18 3.59 .28 1.90 1.71 .85 1.53 2.25 .88 .49 4.35 .67 2.74 .79.05 !.22 !.21 !.05 !.48 !.07 .34 .56 !.55 .28 .23 !.07 .18 .35 !.05 !.31 .64 !.17 .44 !.10 256.94.84 Box-and-whisker plots from SPSS software for these data are shown in Figure 11.1.1. The raw data are clearly skewed, and an outlier is identified (observation 25). A log10 transformation, which is often useful for such skewed data, removes the magnitude of the outlier and results in a distribution that is much more nearly symmetric about the median. Therefore, the transformed data could be used in lieu of the raw data for con- structing the regression model. Though symmetric data do not, necessarily, imply that the data are normal, they do result in a more appropriate model. Formal tests of normal- ity, as previously mentioned, should always be carried out prior to analysis. ■ Unequal Error Variances When the variances of the error terms are not equal, we may obtain a satisfactory equation for the model, but, because the assumption that the error variances are equal is violated, we will not be able to perform appropriate hypothesis tests on the model coefficients. Just as was the case in overcoming the non-normality problem, transformations of the regression variables may reduce the impact of unequal error variances.538 CHAPTER 11 REGRESSION ANALYSIS: SOME ADDITIONAL TECHNIQUES FIGURE 11.1.1 Box-and-whisker plots of data from Example 11.1.1. Correlated Independent Variables Multicollinearity is a common problem that arises when one attempts to build a model using many independent variables. Multicollinearity occurs when there is a high degree of correlation among the independent variables. For example, imagine that we want to find an equation relating height and weight to blood pressure. A common variable that is derived from height and weight is called the body mass index (BMI). If we attempt to find an equation relating height, weight, and BMI to blood pressure, we can expect to run into analytical problems because BMI, by definition, is highly correlated with both height and weight. The problem arises mathematically when the solutions for the regression coefficients are derived. Since the data are correlated, solutions may not be found that are unique to a given model. The least complex solution to multicollinearity is to calculate correlations among all of the independent variables and to retain only those variables that are not highly correlated. A conservative rule of thumb to remove redundancy in the data set is to elim- inate variables that are related to others with a significant correlation coefficient above 0.7. EXAMPLE 11.1.2 A study of obesity and metabolic syndrome used data collected from 15 students, and included systolic blood pressure (SBP), weight, and BMI. These data are presented in Table 11.1.2. Correlations for the three variables are shown in Figure 11.1.2. The very large and significant correlation between the variables weight and BMI suggests that including both of these variables in the model is inappropriate because of the high level of redundancy in the information provided by these variables. This makes logical sense since BMI is a function of weight. The researcher is now faced with the task of deciding which of the variables to retain for constructing the regression model.11.2 QUALITATIVE INDEPENDENT VARIABLES 539 TABLE 11.1.2 Data from a Random Sample of 15 Students Case No.SBPWeight (lbs.)BMI 1 2 3 4 5126 129 126 123 124125 130 132 200 32124.41 23.77 20.07 27.12 39.07 6 7 8 9 10 11 12 13 14 15125 127 125 123 119 127 126 122 126 125100 138 138 149 180 184 251 197 107 12520.90 22.96 24.44 23.33 25.82 26.40 31.37 26.72 20.22 23.62 Correlations: SBP, Weight, BMI SBP Weight p-value&0.289 0.296 BMI p-value&0.213 0.447 FIGURE 11.1.2 Example 11.1.2. Weight 0.962 0.000 Correlations calculated in MINITAB software for the data in ■ 11.2 QUALITATIVE INDEPENDENT VARIABLES The independent variables considered in the discussion in Chapter 10 were all quantita- tive; that is, they yielded numerical values that were either counts or measurements in the usual sense of the word. For example, some of the independent variables used in our examples and exercises were age, education level, collagen porosity, and collagen ten- sile strength. Frequently, however, it is desirable to use one or more qualitative variables as independent variables in the regression model. Qualitative variables, it will be recalled, are those variables whose “values” are categories and that convey the concept of attrib- ute rather than amount or quantity. The variable marital status, for example, is a quali- tative variable whose categories are “single,” “married,” “widowed,” and “divorced.” Other examples of qualitative variables include sex (male or female), diagnosis, race, occupation, and immunity status to some disease. In certain situations an investigator540 CHAPTER 11 REGRESSION ANALYSIS: SOME ADDITIONAL TECHNIQUES may suspect that including one or more variables such as these in the regression equa- tion would contribute significantly to the reduction of the error sum of squares and thereby provide more precise estimates of the parameters of interest. Suppose, for example, that we are studying the relationship between the dependent variable systolic blood pressure and the independent variables weight and age. We might also want to include the qualitative variable sex as one of the independent variables. Or suppose we wish to gain insight into the nature of the relationship between lung capac- ity and other relevant variables. Candidates for inclusion in the model might consist of such quantitative variables as height, weight, and age, as well as qualitative vari- ables such as sex, area of residence (urban, suburban, rural), and smoking status (cur- rent smoker, ex-smoker, never smoked). Dummy Variables In order to incorporate a qualitative independent variable in the multiple regression model, it must be quantified in some manner. This may be accomplished through the use of what are known as dummy variables. DEFINITION A dummy variable is a variable that assumes only a finite number of values (such as 0 or 1) for the purpose of identifying the different cate- gories of a qualitative variable. The term “dummy” is used to indicate the fact that the numerical values (such as 0 and 1) assumed by the variable have no quantitative meaning but are used merely to identify different categories of the qualitative variable under consideration. Qualitative variables are sometimes called indicator variables, and when there are only two cate- gories, they are sometimes called dichotomous variables. The following are some examples of qualitative variables and the dummy variables used to quantify them: Qualitative Variable Sex (male, female): Place of residence (urban, rural, suburban): Smoking status \[current smoker, ex-smoker (has not smoked for 5 years or less), ex-smoker (has not smoked for more than 5 years), never smoked\]: Dummy Variable x1 = e x1 = e x2 = e x1 = e x2 = e x3 = e 1 for male 0 for female 1 for urban 0 for rural and suburban 1 for rural 0 for urban and suburban 1 for current smoker 0 for otherwise 1 for ex-smoker 1… 5 years2 0 otherwise 1 for ex-smoker 1 7 5 years2 0 otherwise11.2 QUALITATIVE INDEPENDENT VARIABLES 541 Note in these examples that when the qualitative variable has k categories, k - 1 dummy variables must be defined for all the categories to be properly coded. This rule is applicable for any multiple regression containing an intercept constant. The variable sex, with two categories, can be quantified by the use of only one dummy variable, while three dummy variables are required to quantify the variable smoking status, which has four categories. The following examples illustrate some of the uses of qualitative variables in mul- tiple regression. In the first example we assume that there is no interaction between the independent variables. Since the assumption of no interaction is not realistic in many instances, we illustrate, in the second example, the analysis that is appropriate when inter- action between variables is accounted for. EXAMPLE 11.2.1 In a study of factors thought to be associated with birth weight, a simple random sample of 100 birth records was selected from the North Carolina 2001 Birth Registry (A-1). Table 11.2.1 shows, for three variables, the data extracted from each record. There are two independent variables: length of gestation (weeks), which is quantitative, and smok- ing status of mother (smoke), a qualitative variable. The dependent variable is birth weight (grams). TABLE 11.2.1 Data from a Simple Random Sample of 100 Births from the North Carolina Birth Registry, Example 11.2.1 Case No.GramsWeeksSmokeCase No.GramsWeeksSmoke 1 2 3 4 5 63147 2977 3119 3487 4111 357240 41 38 38 39 410 0 0 0 0 051 52 53 54 55 563232 3317 2863 3175 3317 371438 40 37 37 40 340 0 0 0 0 0 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 223487 3147 3345 2665 1559 3799 2750 3487 3317 3544 3459 2807 3856 3260 2183 320440 41 38 34 34 38 38 40 38 43 45 37 40 40 42 380 0 1 0 0 0 0 0 0 1 0 0 0 0 1 057 58 59 60 61 62 63 64 65 66 67 68 69 70 71 722240 3345 3119 2920 3430 3232 3430 4139 3714 1446 3147 2580 3374 3941 2070 334536 39 39 37 41 35 38 39 39 28 39 31 37 40 37 40 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 (Continued )542 CHAPTER 11 REGRESSION ANALYSIS: SOME ADDITIONAL TECHNIQUES Case No.GramsWeeksSmokeCase No.GramsWeeksSmoke 23 24 25 26 27 283005 3090 3430 3119 3912 357236 40 39 40 39 400 1 0 0 0 073 74 75 76 77 783600 3232 3657 3487 2948 272240 41 38 39 38 400 0 1 0 0 0 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 503884 3090 2977 3799 4054 3430 3459 3827 3147 3289 3629 3657 3175 3232 3175 3657 3600 3572 709 624 2778 357241 38 42 37 40 38 41 39 44 38 36 36 41 43 36 40 39 40 25 25 36 350 0 0 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 079 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 1003771 3799 1871 3260 3969 3771 3600 2693 3062 2693 3033 3856 4111 3799 3147 2920 4054 2296 3402 1871 4167 340240 45 33 39 38 40 40 35 45 36 41 42 40 39 38 36 40 36 38 33 41 370 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 Source: John P. Holcomb, sampled and coded from North Carolina Birth Registry data found at www.irss.unc.edu/ncvital/bfd1down.html. Solution: For the analysis, we quantify smoking status by means of a dummy vari- able that is coded 1 if the mother is a smoker and 0 if she is a nonsmoker. The data in Table 11.2.1 are plotted as a scatter diagram in Figure 11.2.1. The scatter diagram suggests that, in general, longer periods of gestation are associated with larger birth weights. To obtain additional insight into the nature of these data, we may enter them into a computer and employ an appropriate program to perform fur- ther analyses. For example, we enter the observations y1 = 3147, x 11 = 40, x 21 = 0, for the first case; y2 = 2977, x 12 = 41, x 22 = 0 for the second case; and so on. Figure 11.2.2 shows the computer output obtained with the use of the MINITAB multiple regression program.11.2 QUALITATIVE INDEPENDENT VARIABLES 543 5000 Birth weight (grams) 4000 3000 2000 1000 0 25 30 35 40 45 50 Length of gestation (weeks) FIGURE 11.2.1 Birth weights and lengths of gestation for 100 births: (") smoking and (!) nonsmoking mothers. The regression equation is grams " &1724 \# 130 x1 & 294 x2 Predictor Constant weeks (x1) smoke (x2)Coef &1724.4 130.05 &294.4 SE Coef 558.8 14.52 135.8 S " 484.6R-Sq " 46.4% T &3.09 8.96 &2.17 P 0.003 0.000 0.033 R-Sq(adj) " 45.3% Analysis of Variance SOURCE Regression Residual Error Total SOURCE x1 x2 FIGURE 11.2.2 Example 11.2.1. DF 2 97 99 DF 1 1 SS 19689185 22781681 42470867 MS 9844593 234863 F 41.92 Seq SS 18585166 1104020 Partial computer printout, MINITAB multiple regression analysis. P 0.000CHAPTER 11 REGRESSION ANALYSIS: SOME ADDITIONAL TECHNIQUES We see in the printout that the multiple regression equation is yN j = bN 0 + bN 1x 1j + bN 2 x 2j yN j = -1724 + 130x 1j - 294bN 2x 2j (11.2.1) To observe the effect on this equation when we wish to consider only the births to smoking mothers, we let x 2j = 1. The equation then becomes yN j = -1724 + 130x1j - 294112 = -2018 + 130x1j (11.2.2) which has a y -intercept of -2018 and a slope of 130. Note that the y-intercept for the new equation is equal to 1bN 0 + bN 12 = 3-1724 + 1-29424 = -2018. Now let us consider only births to nonsmoking mothers. When we let x 2 = 0, our regression equation reduces to yNj = -1724 + 130x1j - 294102 = -1724 + 130x1j (11.2.3) The slope of this equation is the same as the slope of the equation for smoking mothers, but the y-intercepts are different. The y-intercept for the equation associated with nonsmoking mothers is larger than the one for the 5000 4000 Smoking mothers Birth weight (grams) 544 3000 Nonsmoking mothers 2000 1000 0 25 30 35 40 45 50 Length of gestation (weeks) FIGURE 11.2.3 Birth weights and lengths of gestation for 100 births and the fitted regression lines: (") smoking and (!) nonsmoking mothers.11.2 QUALITATIVE INDEPENDENT VARIABLES 545 smoking mothers. These results show that for this sample, babies born to mothers who do not smoke weighed, on the average, more than babies born to mothers who do smoke, when length of gestation is taken into account. The amount of the difference, on the average, is 294 grams. Stated another way, we can say that for this sample, babies born to mothers who smoke weighed, on the average, 294 grams less than the babies born to mothers who do not smoke, when length of gestation is taken into account. Figure 11.2.3 shows the scatter diagram of the original data along with a plot of the two regression lines (Equations 11.2.2 and 11.2.3). ■ EXAMPLE 11.2.2 At this point a question arises regarding what inferences we can make about the sam- pled population on the basis of the sample results obtained in Example 11.2.1. First of all, we wish to know if the sample difference of 294 grams is significant. In other words, does smoking have an effect on birth weight? We may answer this question through the following hypothesis testing procedure. Solution: 1. Data. The data are as given in Example 11.2.1. 2. Assumptions. We presume that the assumptions underlying multiple regression analysis are met. 3. Hypotheses. H0 : b 2 = 0; HA : b 2 Z 0. Suppose we let a = .05. 4. Test statistic. The test statistic is t = 1bN 2 - 02\>sbN . 2 5. Distribution of test statistic. When the assumptions are met and H0 is true the test statistic is distributed as Student’s t with 97 degrees of freedom. 6. Decision rule. We reject H0 if the computed t is either greater than or equal to 1.9848 or less than or equal to -1.9848 (obtained by inter- polation). 7. Calculation of test statistic. The calculated value of the test statistic appears in Figure 11.2.2 as the t ratio for the coefficient associated with the variable appearing in Column 3 of Table 11.2.1. This coefficient, of course, is bN 2. We see that the computed t is -2.17. 8. Statistical decision. Since -2.17 6 -1.9848, we reject H0. 9. Conclusion. We conclude that, in the sampled population, whether the mothers smoke is associated with a reduction in the birth weights of their babies. ■ 10. p value. For this test we have p = .033 from Figure 11.2.2. A Confidence Interval for B 2 Given that we are able to conclude that in the sampled population the smoking status of the mothers does have an effect on the birth weights of their babies, we may now inquire as to the magnitude of the effect. Our546 CHAPTER 11 REGRESSION ANALYSIS: SOME ADDITIONAL TECHNIQUES best point estimate of the average difference in birth weights, when length of gestation is taken into account, is 294 grams in favor of babies born to mothers who do not smoke. We may obtain an interval estimate of the mean amount of the difference by using infor- mation from the computer printout by means of the following expression: bN 2 ; tsbN 2 For a 95 percent confidence interval, we have -294.4 ; 1.98481135.82 -563.9, -24.9 Thus, we are 95 percent confident that the difference is somewhere between about 564 grams and 25 grams. Advantages of Dummy Variables The reader may have correctly surmised that an alternative analysis of the data of Example 11.2.1 would consist of fitting two separate regression equations: one to the subsample of mothers who smoke and another to the subsample of those who do not. Such an approach, however, lacks some of the advantages of the dummy variable technique and is a less desirable procedure when the latter procedure is valid. If we can justify the assumption that the two separate regres- sion lines have the same slope, we can get a better estimate of this common slope through the use of dummy variables, which entails pooling the data from the two subsamples. In Example 11.2.1 the estimate using a dummy variable is based on a total sample size of 100 observations, whereas separate estimates would be based on a sample of 85 smok- ers and only 15 nonsmokers. The dummy variables approach also yields more precise inferences regarding other parameters since more degrees of freedom are available for the calculation of the error mean square. Use of Dummy Variables: Interaction Present Now let us consider the situation in which interaction between the variables is assumed to be present. Sup- pose, for example, that we have two independent variables: one quantitative variable X1 and one qualitative variable with three response levels yielding the two dummy variables X2 and X3. The model, then, would be yj = b 0 + b 1X1j + b 2X2j + b 3X3j + b 4X1j X2j + b 5X1j X3j + Pj (11.2.4) in which b 4X1j X2j and b 5X1j X3j are called interaction terms and represent the interaction between the quantitative and the qualitative independent variables. Note that there is no need to include in the model the term containing X2j X3j ; it will always be zero because when X2 = 1, X3 = 0, and when X3 = 1, X2 = 0. The model of Equation 11.2.4 allows for a different slope and Y-intercept for each level of the qualitative variable. Suppose we use dummy variable coding to quantify the qualitative variable as follows: 1 for level 1 0 otherwise 1 for level 2 X3 = e 0 otherwise X2 = e547 11.2 QUALITATIVE INDEPENDENT VARIABLES The three sample regression equations for the three levels of the qualitative variable, then, are as follows: Level 1 (X2 " 1, X3 " 0) yNj = bN 0 + bN 1x1j + bN 2112 + bN 3102 + bN 4x1j 112 + bN 5x1j 102 = bN 0 + bN 1x1j + bN 2 + bN 4 x1j = 1bN 0 + bN 22 + 1bN 1 + bN 42x1j (11.2.5) Level 2 (X2 " 0, X3 " 1) yNj = bN 0 + bN 1x1j + bN 2102 + bN 3112 + bN 4x1j 102 + bN 5x1j 112 = bN 0 + bN 1x 1j + bN 3 + bN 5 x 1j = 1bN 0 + bN 32 + 1bN 1 + bN 52x1j (11.2.6) Level 3 (X2 " 0, X3 " 0) yNj = bN 0 + bN 1x1j + bN 2102 + bN 3102 + bN 4 x1j 102 + bN 5 x1j 102 = bN 0 + bN 1x1j (11.2.7) Let us illustrate these results by means of an example. EXAMPLE 11.2.3 A team of mental health researchers wishes to compare three methods (A, B, and C) of treating severe depression. They would also like to study the relationship between age and treatment effectiveness as well as the interaction (if any) between age and treatment. Each member of a simple random sample of 36 patients, comparable with respect to diagnosis and severity of depression, was randomly assigned to receive treatment A, B, or C. The results are shown in Table 11.2.2. The dependent variable Y is treatment effec- tiveness, the quantitative independent variable X1 is patient’s age at nearest birthday, and the independent variable type of treatment is a qualitative variable that occurs at three levels. The following dummy variable coding is used to quantify the qualitative variable: 1 for treatment A 0 otherwise 1 for treatment B X3 = e 0 otherwise X2 = e The scatter diagram for these data is shown in Figure 11.2.4. Table 11.2.3 shows the data as they were entered into a computer for analysis. Figure 11.2.5 contains the printout of the analysis using the MINITAB multiple regression program. Solution: Now let us examine the printout to see what it provides in the way of insight into the nature of the relationships among the variables. The least-squares equation is yNj = 6.21 + 1.03x1j + 41.3x 2j + 22.7x 3j - .703x1j x 2j - .510x1j x 3j548 CHAPTER 11 REGRESSION ANALYSIS: SOME ADDITIONAL TECHNIQUES TABLE 11.2.2 Data for Example 11.2.3 Measure of EffectivenessAgeMethod of Treatment 56 41 40 2821 23 30 19A B B C 55 25 46 71 48 63 52 62 50 45 58 46 58 34 65 55 57 59 64 61 62 36 69 47 73 64 60 62 71 62 7028 23 33 67 42 33 33 56 45 43 38 37 43 27 43 45 48 47 48 53 58 29 53 29 58 66 67 63 59 51 67A C B C B A A C C B A C B C A B B C A A B C A B A B B A C C A 7163C The three regression equations for the three treatments are as follows: Treatment A (Equation 11.2.5) yNj = 16.21 + 41.32 + 11.03 - .7032x 1j = 47.51 + .327x 1j11.2 QUALITATIVE INDEPENDENT VARIABLES 549 80 75 70 Treatment effectiveness 65 60 55 50 45 40 35 30 25 15 20 25 30 35 40 45 50 55 60 65 70 75 80 Age FIGURE 11.2.4 Scatter diagram of data for Example 11.2.3: (!) treatment A, (") treatment B, (#) treatment C. Treatment B (Equation 11.2.6) yN j = 16.21 + 22.72 + 11.03 - .5102x1j = 28.91 + .520x1j Treatment C (Equation 11.2.7) yN j = 6.21 + 1.03x1j Figure 11.2.6 contains the scatter diagram of the original data along with the regression equations for the three treatments. Visual inspection of Figure 11.2.6 suggests that treatments A and B do not differ greatly with respect to their slopes, but their y-intercepts are considerably different. The graph suggests that treatment A is better than treatment B for younger patients, but the difference is less dramatic with older patients. Treatment C appears to be decidedly less desirable than both treatments A and B for younger patients but is about as effective as treatment B for older patients. These subjective impressions are compatible with the contention that there is interaction between treatments and age. Inference Procedures The relationships we see in Figure 11.2.6, however, are sample results. What can we conclude about the population from which the sample was drawn? For an answer let us look at the t ratios on the computer printout in Figure 11.2.5. Each of these is the test statistic bN i - 0 t = sbN i550 CHAPTER 11 REGRESSION ANALYSIS: SOME ADDITIONAL TECHNIQUES TABLE 11.2.3 Data for Example 11.2.3 Coded for Computer Analysis YX1X2X3X1X2X1X3 56 55 63 52 5821 28 33 33 381 1 1 1 10 0 0 0 021 28 33 33 380 0 0 0 0 65 64 61 69 73 62 70 41 40 46 48 45 58 55 57 62 47 64 60 28 25 71 62 50 46 34 59 36 71 6243 48 53 53 58 63 67 23 30 33 42 43 43 45 48 58 29 66 67 19 23 67 56 45 37 27 47 29 59 511 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 00 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 043 48 53 53 58 63 67 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 00 0 0 0 0 0 0 23 30 33 42 43 43 45 48 58 29 66 67 0 0 0 0 0 0 0 0 0 0 0 71630000 for testing H0 : b i = 0. We see by Equation 11.2.5 that the y-intercept of the regression line for treatment A is equal to bN 0 + bN 2. Since the t ratio of 8.12 for testing H0 : b 2 = 0 is greater than the critical t of 2.0423 (for a = .05), we can reject H0 that b 2 = 0 and conclude that the y-intercept of the population regression line for treatment A is differ- ent from the y-intercept of the population regression line for treatment C, which has a11.2 QUALITATIVE INDEPENDENT VARIABLES 551 The regression equation is y = 6.21 + 1.03 x1 + 41.3 x2 + 22.7 x3 - 0.703 x4 - 0.510 x5 Predictor Constant x1 x2 x3 x4 x5 Coef 6.211 1.03339 41.304 22.707 -0.7029 -0.5097 s = 3.925 Stdev 3.350 0.07233 5.085 5.091 0.1090 0.1104 R-sq = 91.4% t-ratio 1.85 14.29 8.12 4.46 -6.45 -4.62 p 0.074 0.000 0.000 0.000 0.000 0.000 R-sq1adj2 = 90.0% Analysis of Variance SOURCE Regression Error TotalDF 5 30 35SS 4932.85 462.15 5395.00 SOURCE x1 x2 x3 x4 x5DF 1 1 1 1 1SEQ SS 3424.43 803.80 1.19 375.00 328.42 FIGURE 11.2.5 MS 986.57 15.40 F 64.04 Computer printout, MINITAB multiple regression analysis, Example 11.2.3. 80 Treatment C 75 Treatment effectiveness p 0.000 70Treatment A 65Treatment B 60 55 50 45 40 35 30 25 15 20 25 30 35 40 45 50 55 60 65 70 75 80 Age FIGURE 11.2.6 Scatter diagram of data for Example 11.2.3 with the fitted regression lines: (!) treatment A, (") treatment B, (#) treatment C.552 CHAPTER 11 REGRESSION ANALYSIS: SOME ADDITIONAL TECHNIQUES y-intercept of b 0. Similarly, since the t ratio of 4.46 for testing H0 : b 3 = 0 is also greater than the critical t of 2.0423, we can conclude (at the .05 level of significance) that the y-intercept of the population regression line for treatment B is also different from the y- intercept of the population regression line for treatment C. (See the y-intercept of Equa- tion 11.2.6.) Now let us consider the slopes. We see by Equation 11.2.5 that the slope of the regression line for treatment A is equal to bN 1 (the slope of the line for treatment C) + bN 4. Since the t ratio of -6.45 for testing H0 : b 4 = 0 is less than the critical t of -2.0423, we can conclude (for a = .05) that the slopes of the population regression lines for treat- ments A and C are different. Similarly, since the computed t ratio for testing H0 : b 5 = 0 is also less than -2.0423, we conclude (for a = .05) that the population regression lines for treatments B and C have different slopes (see the slope of Equation 11.2.6). Thus we conclude that there is interaction between age and type of treatment. This is reflected by a lack of parallelism among the regression lines in Figure 11.2.6. ■ Another question of interest is this: Is the slope of the population regression line for treatment A different from the slope of the population regression line for treatment B? To answer this question requires computational techniques beyond the scope of this text. The interested reader is referred to books devoted specifically to regression analysis. In Section 10.4 the reader was warned that there are problems involved in making multiple inferences from the same sample data. Again, books on regression analysis are available that may be consulted for procedures to be followed when multiple inferences, such as those discussed in this section, are desired. We have discussed only two situations in which the use of dummy variables is appropriate. More complex models involving the use of one or more qualitative inde- pendent variables in the presence of two or more quantitative variables may be appro- priate in certain circumstances. More complex models are discussed in the many books devoted to the subject of multiple regression analysis. EXERCISES For each exercise do the following: (a) Draw a scatter diagram of the data using different symbols for the different categorical variables. (b) Use dummy variable coding and regression to analyze the data. (c) Perform appropriate hypothesis tests and construct appropriate confidence intervals using your choice of significance and confidence levels. (d) Find the p value for each test that you perform. 11.2.1 For subjects undergoing stem cell transplants, dendritic cells (DCs) are antigen-presenting cells that are critical to the generation of immunologic tumor responses. Bolwell et al. (A-2) studied lymphoid DCs in 44 subjects who underwent autologous stem cell transplantation. The outcome variable is the concentration of DC2 cells as measured by flow cytometry. One of the independent variables is theEXERCISES 553 age of the subject (years), and the second independent variable is the mobilization method. During chemotherapy, 11 subjects received granulocyte colony-stimulating factor (G-CSF) mobilizer (mg/kg/day) and 33 received etoposide (2 g\>m2). The mobilizer is a kind of blood progenitor cell that triggers the formation of the DC cells. The results were as follows: G-CSF Etoposide DCAgeDCAgeDCAgeDCAge 6.16 6.14 5.66 8.28 2.99 8.99 4.04 6.02 10.14 27.25 8.8665 55 57 47 66 24 59 60 66 63 693.18 2.58 1.69 2.16 3.26 1.61 6.34 2.43 2.86 7.74 11.3370 64 65 55 51 53 24 53 37 65 194.24 4.86 4.05 5.07 4.26 11.95 1.88 6.10 0.64 2.21 6.2660 40 48 50 23 26 59 24 52 54 434.09 2.86 2.25 0.70 0.23 1.31 1.06 3.14 1.87 8.21 1.4436 51 54 50 62 56 31 48 69 62 60 Source: Lisa Rybicki, M.S. Used with permission. 11.2.2 According to Pandey et al. (A-3) carcinoma of the gallbladder is not infrequent. One of the pri- mary risk factors for gallbladder cancer is cholelithiasis, the asymptomatic presence of stones in the gallbladder. The researchers performed a case-control study of 50 subjects with gallbladder cancer and 50 subjects with cholelithiasis. Of interest was the concentration of lipid peroxidation products in gallbladder bile, a condition that may give rise to gallbladder cancer. The lipid perox- idation product melonaldehyde (MDA, mg/mg) was used to measure lipid peroxidation. One of the independent variables considered was the cytochrome P-450 concentration (CYTO, nmol/mg). Researchers used disease status (gallbladder cancer vs. cholelithiasis) and cytochrome P-450 con- centration to predict MDA. The following data were collected. Cholelithiasis Gallbladder Cancer MDACYTOMDACYTOMDACYTOMDACYTO 0.68 0.16 0.34 3.86 0.98 3.31 1.11 4.46 1.16 1.2712.60 4.72 3.08 5.23 4.29 21.46 10.07 5.03 11.60 9.0011.62 2.71 3.39 6.10 1.95 3.80 1.72 9.31 3.25 0.624.83 3.25 7.03 9.64 9.02 7.76 3.68 11.56 10.33 5.721.60 4.00 4.50 0.77 2.79 8.78 2.69 0.80 3.43 2.7322.74 4.63 9.83 8.03 9.11 7.50 18.05 3.92 22.20 11.689.20 0.69 10.20 3.80 1.90 2.00 7.80 16.10 0.98 2.858.99 5.86 28.32 4.76 8.09 21.05 20.22 9.06 35.07 29.50 (Continued )554 CHAPTER 11 REGRESSION ANALYSIS: SOME ADDITIONAL TECHNIQUES Cholelithiasis Gallbladder Cancer MDACYTOMDACYTOMDACYTOMDACYTO 1.38 3.83 0.16 0.56 1.95 0.08 2.17 0.00 1.35 3.22 1.69 4.90 1.33 0.64 5.216.13 6.06 6.45 4.78 34.76 15.53 12.23 0.93 3.81 6.39 14.15 5.67 8.49 2.27 12.352.46 7.63 4.60 12.21 1.03 1.25 2.13 0.98 1.53 3.91 2.25 1.67 5.23 2.79 1.434.01 6.09 4.53 19.01 9.62 7.59 12.33 5.26 5.69 7.72 7.61 4.32 17.79 15.51 12.431.41 6.08 5.44 4.25 1.76 8.39 2.82 5.03 7.30 4.97 1.11 13.27 7.73 3.69 9.2619.10 36.70 48.30 4.47 8.83 5.49 3.48 7.98 27.04 16.02 6.14 13.31 10.03 17.23 9.293.50 4.80 1.89 2.90 0.87 4.25 1.43 6.75 4.30 0.59 5.30 1.80 3.50 4.98 6.9845.06 8.99 48.15 10.12 17.98 37.18 19.09 6.05 17.05 7.79 6.78 16.03 5.07 16.60 19.89 Source: Manoj Pandey, M.D. Used with permission. 11.2.3 The purpose of a study by Krantz et al. (A-4) was to investigate dose-related effects of methadone in subjects with torsades de pointes, a polymorphic ventricular tachycardia. In the study of 17 subjects, 10 were men (sex = 0) and seven were women (sex = 1). The outcome variable, is the QTc interval, a measure of arrhythmia risk. The other independent variable, in addition to sex, was methadone dose (mg/day). Measurements on these variables for the 17 subjects were as follows. SexDose (mg/day)QTc (msec) 0 0 0 1 1 1 0 0 1 1 1 1 1 1 0 0 11000 550 97 90 85 126 300 110 65 650 600 660 270 680 540 600 330600 625 560 585 590 500 700 570 540 785 765 611 600 625 650 635 522 Source: Mori J. Krantz, M.D. Used with permission.EXERCISES 11.2.4 555 Refer to Exercise 9.7.2, which describes research by Reiss et al. (A-5), who collected samples from 90 patients and measured partial thromboplastin time (aPTT) using two different methods: the CoaguChek point-of-care assay and standard laboratory hospital assay. The subjects were also classi- fied by their medication status: 30 receiving heparin alone, 30 receiving heparin with warfarin, and 30 receiving warfarin and enoxaparin. The data are as follows. Heparin Warfarin Warfarin and Enoxaparin CoaguChek aPTTHospital aPTTCoaguChek aPTTHospital aPTTCoaguChek aPTTHospital aPTT 49.3 57.9 59.0 77.3 42.3 44.3 90.0 55.4 20.3 28.7 64.3 90.4 64.3 89.8 74.7 150.0 32.4 20.9 89.5 44.7 61.0 36.4 52.9 57.5 39.1 74.8 32.5 125.7 77.1 143.871.4 86.4 75.6 54.5 57.7 59.5 77.2 63.3 27.6 52.6 101.6 89.4 66.2 69.8 91.3 118.8 30.9 65.2 77.9 91.5 90.5 33.6 88.0 69.9 41.0 81.7 33.3 142.9 98.2 108.318.0 31.2 58.7 75.2 18.0 82.6 29.6 82.9 58.7 64.8 37.9 81.2 18.0 38.8 95.4 53.7 128.3 60.5 150.0 38.5 58.9 112.8 26.7 49.7 85.6 68.8 18.0 92.6 46.2 60.577.0 62.2 53.2 53.0 45.7 81.1 40.9 75.4 55.7 54.0 79.4 62.5 36.5 32.8 68.9 71.3 111.1 80.5 150.0 46.5 89.1 66.7 29.5 47.8 63.3 43.5 54.0 100.5 52.4 93.756.5 50.7 37.3 64.8 41.2 90.1 23.1 53.2 27.3 67.5 33.6 45.1 56.2 26.0 67.8 40.7 36.2 60.8 30.2 18.0 55.6 18.0 18.0 78.3 75.3 73.2 42.0 49.3 22.8 35.846.5 34.9 28.0 52.3 37.5 47.1 27.1 40.6 37.8 50.4 34.2 34.8 44.2 28.2 46.3 41.0 35.7 47.2 39.7 31.3 53.0 27.4 35.7 62.0 36.7 85.3 38.3 39.8 42.3 36.0 Source: Curtis E. Haas, Pharm.D. Used with permission. Use the multiple regression to predict the hospital aPTT from the CoaguCheck aPTT level as well as the medication received. Is knowledge of medication useful in the prediction? Let a = .05 for all tests.556CHAPTER 11 REGRESSION ANALYSIS: SOME ADDITIONAL TECHNIQUES 11.3VARIABLE SELECTION PROCEDURES Health sciences researchers contemplating the use of multiple regression analysis to solve problems usually find that they have a large number of variables from which to select the independent variables to be employed as predictors of the dependent variable. Such investigators will want to include in their model as many variables as possible in order to maximize the model’s predictive ability. The investigator must realize, however, that adding another independent variable to a set of independent variables always increases the coefficient of determination R 2. Therefore, independent variables should not be added to the model indiscriminately, but only for good reason. In most situations, for example, some potential predictor variables are more expensive than others in terms of data- collection costs. The cost-conscious investigator, therefore, will not want to include an expensive variable in a model unless there is evidence that it makes a worthwhile contribution to the predictive ability of the model. The investigator who wishes to use multiple regression analysis most effectively must be able to employ some strategy for making intelligent selections from among those potential predictor variables that are available. Many such strategies are in cur- rent use, and each has its proponents. The strategies vary in terms of complexity and the tedium involved in their employment. Unfortunately, the strategies do not always lead to the same solution when applied to the same problem. Stepwise Regression Perhaps the most widely used strategy for selecting inde- pendent variables for a multiple regression model is the stepwise procedure. The proce- dure consists of a series of steps. At each step of the procedure each variable then in the model is evaluated to see if, according to specified criteria, it should remain in the model. Suppose, for example, that we wish to perform stepwise regression for a model containing k predictor variables. The criterion measure is computed for each variable. Of all the variables that do not satisfy the criterion for inclusion in the model, the one that least satisfies the criterion is removed from the model. If a variable is removed in this step, the regression equation for the smaller model is calculated and the criterion meas- ure is computed for each variable now in the model. If any of these variables fail to sat- isfy the criterion for inclusion in the model, the one that least satisfies the criterion is removed. If a variable is removed at this step, the variable that was removed in the first step is reentered into the model, and the evaluation procedure is continued. This process continues until no more variables can be entered or removed. The nature of the stepwise procedure is such that, although a variable may be deleted from the model in one step, it is evaluated for possible reentry into the model in subsequent steps. MINITAB’s STEPWISE procedure, for example, uses the associated F statistic as the evaluative criterion for deciding whether a variable should be deleted or added to the model. Unless otherwise specified, the cutoff value is F = 4. The printout of the STEPWISE results contains t statistics (the square root of F ) rather than F statistics. At each step MINITAB calculates an F statistic for each variable then in the model. If the F statistic for any of these variables is less than the specified cutoff value (4 if some other value is not specified), the variable with the smallest F is removed from the model. The regression equation is refitted for the reduced model, the results are printed, and11.3 VARIABLE SELECTION PROCEDURES 557 the procedure goes to the next step. If no variable can be removed, the procedure tries to add a variable. An F statistic is calculated for each variable not then in the model. Of these variables, the one with the largest associated F statistic is added, provided its F statistic is larger than the specified cutoff value (4 if some other value is not speci- fied). The regression equation is refitted for the new model, the results are printed, and the procedure goes on to the next step. The procedure stops when no variable can be added or deleted. The following example illustrates the use of the stepwise procedure for selecting variables for a multiple regression model. EXAMPLE 11.3.1 A nursing director would like to use nurses’ personal characteristics to develop a regres- sion model for predicting the job performance ( JOBPER). The following variables are available from which to choose the independent variables to include in the model: X1 = assertiveness 1ASRV2 X2 = enthusiasm 1ENTH2 X3 = ambition 1AMB2 X4 = communication skills 1COMM2 X5 = problem-solving skills 1PROB2 X6 = initiative 1INIT2 We wish to use the stepwise procedure for selecting independent variables from those available in the table to construct a multiple regression model for predicting job performance. Solution: Table 11.3.1 shows the measurements taken on the dependent variable, JOBPER, and each of the six independent variables for a sample of 30 nurses. TABLE 11.3.1 Measurements on Seven Variables for Examples 11.3.1 YX1X2X3X4X5X6 45 65 73 63 83 45 60 7374 65 71 64 79 56 68 7629 50 67 44 55 48 41 4940 64 79 57 76 54 66 6566 68 81 59 76 59 71 7593 74 87 85 84 50 69 6747 49 33 37 33 42 37 43 (Continued )558 CHAPTER 11 REGRESSION ANALYSIS: SOME ADDITIONAL TECHNIQUES YX1X2X3X4X5X6 74 69 66 69 71 70 79 83 75 67 67 52 52 66 55 42 65 68 80 50 87 8483 62 54 61 63 84 78 65 86 61 71 59 71 62 67 65 55 78 76 58 86 8371 44 52 46 56 82 53 49 63 64 45 67 32 51 51 41 41 65 57 43 70 3877 57 67 66 67 68 82 82 79 75 67 64 44 72 60 45 58 73 84 55 81 8376 67 63 64 60 64 84 65 84 60 80 69 48 71 68 55 71 93 85 56 82 6984 81 68 75 64 78 78 55 80 81 86 79 65 81 81 58 76 77 79 84 75 7933 43 36 43 35 37 39 38 41 45 48 54 43 43 39 51 35 42 35 40 30 41 We use MINITAB to obtain a useful model by the stepwise proce- dure. Observations on the dependent variable job performance (JOBPER) and the six candidate independent variables are stored in MINITAB Columns 1 through 7, respectively. Figure 11.3.1 shows the appropriate MINITAB procedure and the printout of the results. To obtain the results in Figure 11.3.1, the values of F to enter and F to remove both were set automatically at 4. In step 1 there are no variables to be considered for deletion from the model. The variable AMB (Column 4) has the largest associated F statistic, which is F = 19.7422 = 94.8676. Since 94.8676 is greater than 4, AMB is added to the model. In step 2 the variable INIT (Column 7) qualifies for addition to the model since its associated F of 1-2.222 = 4.84 is greater than 4 and it is the variable with the largest associated F statistic. It is added to the model. After step 2 no other variable could be added or deleted, and the procedure stopped. We see, then, that the model chosen by the stepwise procedure is a two- independent-variable model with AMB and INIT as the independent vari- ables. The estimated regression equation is yN = 31.96 + .787x 3 - .45x 6 ■11.3 VARIABLE SELECTION PROCEDURES 559 Dialog box:Session command: Stat ➤ Regression ➤ StepwiseMTB \> Stepwise C1 C2–C7; SUBC\> FEnter 4.0; SUBC\> FRemove 4.0. Type C1 in Response and C2–C7 in Predictors. Stepwise Regression F-to-Enter: 4.00 F-to-Remove: 4.00 Response is C1 on 6 predictors, with N = 30 Step 1 Constant 7.226 C4 T-Ratio 0.888 9.74 C7 T-Ratio S R-Sq 2 31.955 0.787 8.13 -0.45 -2.20 5.90 77.21 5.53 80.68 FIGURE 11.3.1 MINITAB stepwise procedure and output for the data of Table 11.3.1. To change the criterion for allowing a variable to enter the model from 4 to some other value K, click on Options, then type the desired value of K in the Enter box. The new criterion F statistic, then, is K rather than 4. To change the criterion for deleting a variable from the model from 4 to some other value K, click on Options, then type the desired value of K in the Remove box. We must choose K to enter to be greater than or equal to K to remove. Though the stepwise selection procedure is a common technique employed by researchers, other methods are available. Following is a brief discussion of two such tools. The final model obtained by each of these procedures is the same model that was found by using the stepwise procedure in Example 11.3.1. Forward Selection This strategy is closely related to the stepwise regression procedure. This method builds a model using correlations. Variables are retained that meet the criteria for inclusion, as in stepwise selection. The first variable entered into the model is the one with the highest correlation with the dependent variable. If this vari- able meets the inclusion criterion, it is retained. The next variable to be considered for inclusion is the one with the highest partial correlation with the dependent variable. If it560 CHAPTER 11 REGRESSION ANALYSIS: SOME ADDITIONAL TECHNIQUES meets the inclusion criteria, it is retained. This procedure continues until all of the inde- pendent variables have been considered. The final model contains all of the independent variables that meet the inclusion criteria. Backward Elimination This model-building procedure begins with all of the variables in the model. This strategy also builds a model using correlations and a prede- termined inclusion criterion based on the F statistic. The first variable considered for removal from the model is the one with the smallest partial correlation coefficient. If this variable does not meet the criterion for inclusion, it is eliminated from the model. The next variable to be considered for elimination is the one with the next lowest partial cor- relation. It will be eliminated if it fails to meet the criterion for inclusion. This proce- dure continues until all variables have been considered for elimination. The final model contains all of the independent variables that meet the inclusion criteria. EXERCISES 11.3.1 Refer to the data of Exercise 10.3.2 reported by Son et al. (A-6), who studied family caregiving in Korea of older adults with dementia. The outcome variable, caregiver burden (BURDEN), was measured by the Korean Burden Inventory (KBI) where scores ranged from 28 to 140 with higher scores indicating higher burden. Perform a stepwise regression analysis on the following independ- ent variables reported by the researchers: CGAGE: caregiver age (years) CGINCOME: caregiver income (Won-Korean currency) CGDUR: caregiver-duration of caregiving (month) ADL: total activities of daily living where low scores indicate the elderly perform activities independently. MEM: memory and behavioral problems with higher scores indicating more problems. COG: cognitive impairment with lower scores indicating a greater degree of cognitive impair- ment. SOCIALSU: total score of perceived social support (25–175, higher values indicating more support). The reported data are as follows. CGAGE 41 30 41 35 37 42 49 39 49 CGINCOMECGDURADLMEMCOGSOCIALSUBURDEN 200 120 300 350 600 90 300 500 30912 36 60 2 48 4 26 16 3039 52 89 57 28 34 42 52 884 33 17 31 35 3 16 6 4118 9 3 7 19 25 17 26 13119 131 141 150 142 148 172 147 9828 68 59 91 70 38 46 57 89 (Continued)EXERCISES CGAGE 40 40 70 49 55 27 39 39 44 33 42 52 48 53 40 35 47 33 41 43 25 35 35 45 36 52 41 40 45 48 50 31 33 30 36 45 32 55 50 37 40 40 49 37 47 41 561 CGINCOMECGDURADLMEMCOGSOCIALSUBURDEN 250 300 60 450 300 309 250 260 250 200 200 200 300 300 300 200 150 180 200 300 309 250 200 200 300 600 230 200 400 75 200 250 300 200 250 500 300 200 309 250 1000 300 300 309 250 20060 36 10 24 18 30 10 12 32 48 12 24 36 12 11 8 60 19 48 36 24 12 6 7 24 60 6 36 96 6 30 30 2 30 6 12 60 24 20 30 21 12 18 18 38 6090 38 83 30 45 47 90 63 34 76 26 68 85 22 82 80 80 81 30 27 72 46 63 45 77 42 60 33 49 89 72 45 73 58 33 34 90 48 47 32 63 76 79 48 90 5524 22 41 9 33 36 17 14 35 33 13 34 28 12 57 51 20 20 7 27 9 15 52 26 57 10 34 14 30 64 31 24 13 16 17 13 42 7 17 13 32 50 44 57 33 113 13 11 24 14 18 0 16 22 23 18 26 10 16 3 3 18 1 17 27 0 22 13 18 0 19 11 14 15 0 3 19 3 15 21 18 6 23 18 15 15 5 11 9 6 20147 146 97 139 127 132 142 131 141 106 144 119 122 110 121 142 101 117 129 142 137 148 135 144 128 148 141 151 124 105 117 111 146 99 115 119 134 165 101 148 132 120 129 133 121 11748 74 78 43 76 72 61 63 77 85 31 79 92 76 91 78 103 99 73 88 64 52 71 41 85 52 68 57 84 91 83 73 57 69 81 71 91 48 94 57 49 88 54 73 87 47 (Continued )562 CHAPTER 11 REGRESSION ANALYSIS: SOME ADDITIONAL TECHNIQUES CGAGE 33 28 33 34 40 54 32 44 44 42 44 25 41 28 24 65 50 40 47 44 37 36 55 45 45 23 42 38 41 25 47 35 59 49 51 54 53 49 44 36 64 51 43 54 29 CGINCOMECGDURADLMEMCOGSOCIALSUBURDEN 1000 309 400 330 200 200 300 280 350 280 500 600 250 1000 200 450 200 309 1000 300 309 300 200 2000 400 200 1000 200 230 200 200 100 150 300 200 250 30 100 300 200 200 120 200 150 30918 12 120 18 18 12 32 66 40 24 14 24 84 30 12 120 12 12 12 24 54 12 12 12 14 36 12 36 36 30 12 12 60 60 48 6 24 36 48 18 48 2 66 96 1983 50 44 79 24 40 35 55 45 46 37 47 28 61 35 68 80 43 53 60 63 28 35 37 82 88 52 30 69 52 59 53 65 90 88 66 60 48 82 88 63 79 71 66 8124 21 31 30 5 20 15 9 28 19 4 29 23 8 31 65 29 8 14 30 22 9 18 33 25 16 15 16 49 17 38 22 56 12 42 12 21 14 41 24 49 34 38 48 6611 25 18 20 22 17 27 21 17 17 21 3 21 7 26 6 10 13 18 16 18 27 14 17 13 0 0 18 12 20 17 21 2 0 6 23 7 13 13 14 5 3 17 13 1140 117 138 163 157 143 125 161 142 135 137 133 131 144 136 169 127 110 120 115 101 139 153 111 131 139 132 147 171 145 140 139 133 145 122 133 107 118 95 100 125 116 124 132 15260 65 57 85 28 40 87 80 49 57 32 52 42 49 63 89 67 43 47 70 99 53 78 112 52 68 63 49 42 56 46 72 95 57 88 81 104 88 115 66 92 97 69 112 88 Source: Gwi-Ryung Son, R.N., Ph.D. Used with permission.EXERCISES 11.3.2 563 Machiel Naeije (A-7) identifies variables useful in predicting maximum mouth opening (MMO, millimeters) for 35 healthy volunteers. The variables examined were: AGE: DOWN_CON: FORW_CON: Gender: MAN_LENG: MAN_WIDT: years downward condylar translation, mm forward condylar translation, mm 0 " Female, 1 " Male mandibular length, mm mandibular width, mm Use the following reported measurements to perform a stepwise regression. AGEDOWN_CONFORW_CONGenderMAN_LENG 21.00 26.00 30.00 28.00 21.00 20.00 21.00 19.00 24.00 18.00 22.00 21.00 20.00 22.00 24.00 22.00 22.00 22.00 19.00 26.00 22.00 24.00 21.00 22.00 22.00 29.00 25.00 20.00 27.00 26.00 23.00 25.00 22.00 31.00 23.004.39 1.39 2.42 &.18 4.10 4.49 2.07 &.77 7.88 6.06 9.37 3.77 1.10 2.52 5.99 5.28 1.25 6.02 1.59 6.05 &1.51 &.41 6.75 4.87 .64 7.18 6.57 1.51 4.64 3.58 6.64 7.61 5.39 5.47 2.6014.18 20.23 13.45 19.66 22.71 13.94 19.35 25.65 18.51 21.72 23.21 23.02 19.59 16.64 17.38 22.57 20.89 20.38 21.63 10.59 20.03 24.55 14.67 17.91 17.60 15.19 17.25 18.01 19.36 16.57 12.47 18.52 11.66 12.85 19.291 0 1 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 0100.86 93.08 98.43 102.95 108.24 98.34 95.57 98.86 98.32 92.70 88.89 104.06 98.18 91.01 96.98 97.86 96.89 98.35 90.65 92.99 108.97 91.85 104.30 93.16 94.18 89.56 105.85 89.29 92.58 98.64 83.70 88.46 94.93 96.81 93.13 Source: Machiel Naeije, D.D.S. Used with permission. MAN_WIDT MMO 121.00 118.29 130.56 125.34 125.19 113.84 115.41 118.30 119.20 111.21 119.07 127.34 111.24 113.81 114.94 111.58 115.16 122.52 118.71 119.10 129.00 100.77 127.15 123.10 113.86 110.56 140.03 121.70 128.01 129.00 130.98 124.97 129.99 132.97 121.03 52.34 51.90 52.80 50.29 57.79 49.41 53.28 59.71 53.32 48.53 51.59 58.52 62.93 57.62 65.64 52.85 64.43 57.25 50.82 40.48 59.68 54.35 47.00 47.23 41.19 42.76 51.88 42.77 52.34 50.45 43.18 41.99 39.45 38.91 49.10564 CHAPTER 11 REGRESSION ANALYSIS: SOME ADDITIONAL TECHNIQUES 11.3.3 One purpose of a study by Connor et al. (A-8) was to examine reactive aggression among chil- dren and adolescents referred to a residential treatment center. The researchers used the Proactive/ Reactive Rating Scale, obtained by presenting three statements to clinicians who examined the subjects. The respondents answered, using a scale from 1 to 5, with 5 indicating that the state- ment almost always applied to the child. An example of a reactive aggression statement is, “When this child has been teased or threatened, he or she gets angry easily and strikes back.” The reactive score was the average response to three statements of this type. With this variable as the outcome variable, researchers also examined the following: AGE (years), VERBALIQ (verbal IQ), STIM (stimulant use), AGEABUSE (age when first abused), CTQ (a measure of hyperactivity in which higher scores indicate higher hyperactivity), TOTALHOS (total hostility as measured by an evaluator, with higher numbers indicating higher hostility). Perform stepwise regression to find the variables most useful in predicting reactive aggression in the following sample of 68 subjects. REACTIVEAGEVERBALIQSTIMAGEABUSECTQTOTALHOS 4.0 3.7 2.3 5.0 2.0 2.7 2.0 3.3 2.0 4.3 4.7 4.3 2.0 4.0 2.7 2.7 2.7 2.0 3.0 2.7 3.7 2.7 2.3 4.0 4.0 4.3 3.7 3.0 4.3 1.0 4.317 12 14 16 15 8 10 12 17 13 15 15 15 13 13 9 18 13 14 13 16 12 14 13 12 13 14 18 14 16 1691 94 105 97 97 91 111 105 101 102 83 66 90 88 98 135 72 93 94 93 73 74 97 91 88 90 104 82 79 93 990 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 00 1 1 1 2 0 0 0 0 1 0 1 2 1 1 0 0 2 2 1 0 1 2 1 1 0 1 0 3 0 10 29 12 9 17 6 6 28 12 8 9 5 3 28 17 30 10 20 10 4 11 10 3 21 14 15 10 1 6 5 218 10 10 11 10 4 6 7 9 11 9 8 8 8 10 11 9 8 11 8 11 7 11 11 9 2 10 7 7 8 11 (Continued )11.4 LOGISTIC REGRESSION 565 REACTIVEAGEVERBALIQSTIMAGEABUSECTQTOTALHOS 2.3 3.0 1.3 3.0 2.3 1.0 3.0 3.3 4.0 1.7 2.3 4.7 1.7 1.7 4.0 5.0 4.3 5.0 3.7 3.3 2.3 1.0 1.7 3.7 2.0 3.7 4.3 2.0 3.0 3.7 4.3 2.3 4.7 3.7 1.3 3.7 1.714 12 15 16 9 15 17 11 11 9 16 15 16 15 12 12 10 9 12 14 16 17 12 12 16 17 14 12 7 12 14 18 12 15 15 7 973 112 102 78 95 124 73 105 89 88 96 76 87 90 76 83 88 98 100 80 84 117 145 123 94 70 113 123 107 78 73 91 91 111 71 102 890 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 02 0 1 1 0 3 1 0 0 1 1 1 2 1 0 1 0 0 0 1 1 2 0 0 2 1 0 0 0 0 1 3 0 0 1 0 08 15 1 26 23 0 1 23 27 2 5 17 0 10 22 19 10 8 6 3 3 1 0 1 6 11 8 2 11 15 2 8 6 2 20 14 249 9 5 8 10 11 10 5 8 8 7 9 4 12 10 7 5 9 4 10 9 9 5 3 6 13 8 8 9 11 8 10 9 9 10 9 6 Source: Daniel F. Connor, M.D. and Lang Lin. Used with permission. 11.4 LOGISTIC REGRESSION Up to now our discussion of regression analysis has been limited to those situations in which the dependent variable is a continuous variable such as weight, blood pres- sure, or plasma levels of some hormone. Much research in the health sciences field566 CHAPTER 11 REGRESSION ANALYSIS: SOME ADDITIONAL TECHNIQUES is motivated by a desire to describe, understand, and make use of the relationship between independent variables and a dependent (or outcome) variable that is discrete. Particularly plentiful are circumstances in which the outcome variable is dichotomous. A dichotomous variable, we recall, is a variable that can assume only one of two mutually exclusive values. These values are usually coded Y = 1 for a success and Y = 0 for a nonsuccess, or failure. Dichotomous variables include those whose two possible values are such categories as died–did not die; cured–not cured; disease occurred–disease did not occur; and smoker–nonsmoker. The health sciences profes- sional who either engages in research or needs to understand the results of research conducted by others will find it advantageous to have, at least, a basic understanding of logistic regression, the type of regression analysis that is usually employed when the dependent variable is dichotomous. The purpose of the present discussion is to provide the reader with this level of understanding. We shall limit our presentation to the case in which there is only one independent variable that may be either continu- ous or dichotomous. The Logistic Regression Model Recall that in Chapter 9 we referred to regression analysis involving only two variables as simple linear regression analysis. The simple linear regression model was expressed by the equation y = b 0 + b 1x + P (11.4.1) in which y is an arbitrary observed value of the continuous dependent variable. When the observed value of Y is my ƒ x , the mean of a subpopulation of Y values for a given value of X, the quantity P, the difference between the observed Y and the regression line (see Figure 9.2.1) is zero, and we may write Equation 11.4.1 as my ƒ x = b 0 + b 1x(11.4.2) E 1y ƒ x2 = b 0 + b 1x(11.4.3) which may also be written as Generally the right-hand side of Equations 11.4.1 through 11.4.3 may assume any value between minus infinity and plus infinity. Even though only two variables are involved, the simple linear regression model is not appropriate when Y is a dichotomous variable because the expected value (or mean) of Y is the probability that Y = 1 and, therefore, is limited to the range 0 through 1, inclusive. Equations 11.4.1 through 11.4.3, then, are incompatible with the reality of the situation. If we let p = P1Y = 12, then the ratio p\>11 - p2 can take on values between 0 and plus infinity. Furthermore, the natural logarithm (ln) of p\>11 - p2 can take on values11.4 LOGISTIC REGRESSION 567 between minus infinity and plus infinity just as can the right-hand side of Equations 11.4.1 through 11.4.3. Therefore, we may write ln c p d = b 0 + b 1x 1 - p (11.4.4) Equation 11.4.4 is called the logistic regression model because the transformation of my ƒ x (that is, p) to ln3p\>11 - p24 is called the logit transformation. Equation 11.4.4 may also be written as p = exp1b 0 + b 1x2 1 + exp1b 0 + b 1x2 (11.4.5) in which exp is the inverse of the natural logarithm. The logistic regression model is widely used in health sciences research. For exam- ple, the model is frequently used by epidemiologists as a model for the probability (inter- preted as the risk) that an individual will acquire a disease during some specified time period during which he or she is exposed to a condition (called a risk factor) known to be or suspected of being associated with the disease. Logistic Regression: Dichotomous Independent Variable The simplest situation in which logistic regression is applicable is one in which both the dependent and the independent variables are dichotomous. The values of the dependent (or outcome) variable usually indicate whether or not a subject acquired a disease or whether or not the subject died. The values of the independent variable indicate the sta- tus of the subject relative to the presence or absence of some risk factor. In the discus- sion that follows we assume that the dichotomies of the two variables are coded 0 and 1. When this is the case the variables may be cross-classified in a table, such as Table 11.4.1, that contains two rows and two columns. The cells of the table contain the fre- quencies of occurrence of all possible pairs of values of the two variables: (1, 1), (1, 0), (0, 1), and (0, 0). An objective of the analysis of data that meet these criteria is a statistic known as the odds ratio. To understand the concept of the odds ratio, we must understand the term TABLE 11.4.1 Two Cross-Classified Dichotomous Variables Whose Values Are Coded 1 and 0 Independent Variable (X ) Dependent Variable (Y )10 1n1,1n1,0 2n0,1n0,0568 CHAPTER 11 REGRESSION ANALYSIS: SOME ADDITIONAL TECHNIQUES odds, which is frequently used by those who place bets on the outcomes of sporting events or participate in other types of gambling activities. Using probability terminology, we may define odds as follows. DEFINITION The odds for success are the ratio of the probability of success to the probability of failure. The odds ratio is a measure of how much greater (or less) the odds are for sub- jects possessing the risk factor to experience a particular outcome. This conclusion assumes that the outcome is a rare event. For example, when the outcome is the con- tracting of a disease, the interpretation of the odds ratio assumes that the disease is rare. Suppose, for example, that the outcome variable is the acquisition or nonacquisition of skin cancer and the independent variable (or risk factor) is high levels of exposure to the sun. Analysis of such data collected on a sample of subjects might yield an odds ratio of 2, indicating that the odds of skin cancer are two times higher among subjects with high levels of exposure to the sun than among subjects without high levels of exposure. Computer software packages that perform logistic regression frequently provide as part of their output estimates of b 0 and b 1 and the numerical value of the odds ratio. As it turns out the odds ratio is equal to exp1b 12. EXAMPLE 11.4.1 LaMont et al. (A-9) tested for obstructive coronary artery disease (OCAD) among 113 men and 35 women who complained of chest pain or possible equivalent to their primary care physician. Table 11.4.2 shows the cross-classification of OCAD with gender. We wish to use logistic regression analysis to determine how much greater the odds are of find- ing OCAD among men than among women. Solution: We may use the SAS® software package to analyze these data. The inde- pendent variable is gender and the dependent variable is status with respect to having obstructive coronary artery disease (OCAD). Use of the SAS® command PROC LOGIST yields, as part of the resulting output, the statis- tics shown in Figure 11.4.1. TABLE 11.4.2 Cases of Obstructive Coronary Artery Disease (OCAD) Classified by Sex Disease MalesFemalesTotal OCAD present OCAD not present92 2115 20107 41 Total11335148 Source: Matthew J. Budoff, M.D. Used with permission.11.4 LOGISTIC REGRESSION 569 The LOGISTIC Procedure Analysis of Maximum Likelihood Estimates Parameter Intercept sex FIGURE 11.4.1 of Table 11.4.2. DF 1 1 Estimate -1.4773 1.7649 Standard ErrorWald Chi-SquarePr \> ChiSq 0.2418 0.418537.3118 17.7844\<.0001 \<.0001 Partial output from use of SAS® command PROC LOGISTIC with the data We see that the estimate of a is -1.4773 and the estimate of b 1 is 1.7649. The estimated odds ratio, then, is OR = exp11.76492 = 5.84. Thus we esti- mate that the odds of finding a case of obstructive coronary artery disease to be almost six times higher among men than women. ■ Logistic Regression: Continuous Independent Variable Now let us consider the situation in which we have a dichotomous dependent variable and a con- tinuous independent variable. We shall assume that a computer is available to perform the calculations. Our discussion, consequently, will focus on an evaluation of the ade- quacy of the model as a representation of the data at hand, interpretation of key elements of the computer printout, and the use of the results to answer relevant questions about the relationship between the two variables. EXAMPLE 11.4.2 According to Gallagher et al. (A-10), cardiac rehabilitation programs offer “informa- tion, support, and monitoring for return to activities, symptom management, and risk factor modification.” The researchers conducted a study to identify among women fac- tors that are associated with participation in such programs. The data in Table 11.4.3 are the ages of 185 women discharged from a hospital in Australia who met eligibility criteria involving discharge for myocardial infarction, artery bypass surgery, angio- plasty, or stent. We wish to use these data to obtain information regarding the relation- ship between age (years) and participation in a cardiac rehabilitation program (ATT = 1, if participated, and ATT = 0, if not). We wish also to know if we may use the results of our analysis to predict the likelihood of participation by a woman if we know her age. Solution: The independent variable is the continuous variable age (AGE), and the dependent or response variable is status with respect to attendance in a car- diac rehabilitation program. The dependent variable is a dichotomous vari- able that can assume one of two values: 0 = did not attend, and 1 = did570 CHAPTER 11 REGRESSION ANALYSIS: SOME ADDITIONAL TECHNIQUES TABLE 11.4.3 Ages of Women Participating and Not Participating in a Cardiac Rehabilitation Program Nonparticipating (ATT " 0) Participating (ATT " 1) 50 5973 7546 5774 5974 5062 74 42 50 34 49 67 44 53 45 79 46 62 58 70 60 67 64 62 50 61 69 74 65 80 69 77 61 72 6771 69 78 69 74 86 49 63 63 72 64 72 79 75 70 73 66 75 73 71 72 69 76 60 79 78 62 7353 40 73 68 72 59 64 78 68 67 55 71 80 75 69 80 79 71 69 78 75 71 69 77 81 78 76 8481 74 77 59 75 68 81 74 65 81 62 85 84 39 52 67 82 84 79 81 74 85 92 69 83 82 85 82 8055 66 49 55 73 41 64 46 65 50 61 64 59 73 73 65 67 60 69 61 79 66 68 61 63 70 68 59 6461 69 76 71 61 46 69 66 57 60 63 63 56 70 70 63 63 65 67 68 84 69 78 69 79 83 67 47 57 66 Source: Robyn Gallagher, R.N., Ph.D. Used with permission. attend. We use the SAS® software package to analyze the data. The SAS® command is PROC LOGISTIC, but if we wish to predict attendance in the cardiac program, we need to use the “descending” option with PROC LOGISTIC. (When you wish to predict the outcome labeled “1” of the dependent variable, use the “descending option” in SAS®. Consult SAS®11.4 LOGISTIC REGRESSION 571 ParameterDFEstimateStandard ErrorWald Chi-SquarePr \> ChiSq Intercept age1 11.8744 &0.03790.9809 0.01463.6518 6.70830.0560 0.0096 FIGURE 11.4.2 Table 11.4.3. Partial SAS® printout of the logistic regression analysis of the data in documentation for further details.) A partial printout of the analysis is shown in Figure 11.4.2. The slope of our regression is -.0379, and the intercept is 1.8744. The regression equation, then, is yN i = 1.8744 - .0379x i where yNi = ln3pN i\>11 - pN i24 and pN i is the predicted probability of attending cardiac rehabilitation for a woman aged x i. Test of H0 that B 1 " 0 We reach a conclusion about the adequacy of the logistic model by testing the null hypothesis that the slope of the regression line is zero. The test statistic is z = bN 1\>sbN 1 where z is the standard normal statistic, bN 1 is the sample slope 1-.03792, and sbN 1 is its standard error (.0146) as shown in Figure 11.4.2. From these numbers we compute z = -.0379\>.0146 = -2.5959, which has an associated two-sided p value of .0094. We conclude, therefore, that the logistic model is adequate. The square of z is chi-square with 1 degree of freedom, a statistic that is shown in Figure 11.4.2. Using the Logistic Regression to Estimate p We may use Equation 11.4.5 and the results of our analysis to estimate p, the probabil- ity that a woman of a given age (within the range of ages represented by the data) will attend a cardiac rehabilitation program. Suppose, for example, that we wish to estimate the probability that a woman who is 50 years of age will participate in a rehabilitation program. Substituting 50 and the results shown in Figure 11.4.2 into Equation 11.4.5 gives pN = exp31.8744 - 1.0379215024 1 + exp31.8744 - 1.0379215024 = .49485 SAS® calculates the estimated probabilities for the given values of X. We can see the estimated probabilities of attending cardiac rehabilitation programs for the age range of the subjects enrolled in the study in Figure 11.4.3. Since the slope was negative, we see a decreasing probability of attending a cardiac rehabilitation program for older women.CHAPTER 11 REGRESSION ANALYSIS: SOME ADDITIONAL TECHNIQUES 0.65 0.60 0.55 0.50 Estimated probability 572 0.45 0.40 0.35 0.30 0.25 0.20 0.15 30 40 50 60 70 80 90 100 Age FIGURE 11.4.3 Example 11.4.2. Estimated probabilities of attendance for ages within the study for ■ Multiple Logistic Regression Practitioners often are interested in the rela- tionships of several independent variables to a response variable. These independent vari- ables may be either continuous or discrete or a combination of the two. Multiple logistic models are constructed by expanding Equations 11.4.1 to 11.4.4. If we begin with Equation 11.4.4, multiple logistic regression can be represented as lnc p d = b 0 + b 1x1j + b 2x 2j + Á + b k x kj 1 - p (11.4.6) Using the logit transformation, we now have p = exp1b 0 + b 1x 1j + b 2x 2j + Á + b k x kj2 1 + exp1b 0 + b 1x 1j + b 2x 2j + Á + b k x kj2 (11.4.7) EXAMPLE 11.4.3 Consider the data presented in Review Exercise 24. In this study by Fils-Aime et al. (A-21), data were gathered and classified with regard to alcohol use. Subjects were classi- fied as having either early (% 25 years) or late (\$ 25 years) onset of excessive alcohol use.11.4 LOGISTIC REGRESSION 573 ParameterBS.E.WaldDfSig.Exp(B) 5-HIAA&.013.0065.8781.015.987 TRYPT.000.000.0001.9831.000 Constant2.0761.0493.9181.0487.970 FIGURE 11.4.3 SPSS output for the data in Example 11.4.3. Levels of cerebrospinal fluid (CSF) tryptophan (TRYPT) and 5-hydroxyindoleacetic acid (5-HIAA) concentrations were also obtained. Solution: The independent variables are the concentrations of TRYPT and 5-HIAA, and the dependent variable is the dichotomous response for onset of exces- sive alcohol use. We use SPSS software to analyze the data. The output is presented in Figure 11.4.3. The equation can be written as yN i = 2.076 - .013x 1j + 0x 2j Note that the coefficient for TRYPT is 0, and therefore it is not playing a role in the model. Test of H0 that B 1 " 0 Tests for significance of the regression coefficients can be obtained directly from Figure 11.4.3. Note that both the constant (intercept) and the 5-HIAA variables are significant in the model (both have p values, noted as “Sig.” in the table, % .05); however, TRYPT is not significant and therefore need not be in the model, suggesting that it is not useful for identifying those study participants with early or late alcoholism onset. As above, probabilities can be easily obtained by using equation 11.4.7 and sub- stituting the values obtained from the analysis. ■ Polytomous Logistic Regression Thus far we have limited our discussion to situations in which there is a dichotomous response variable (e.g., successful or unsuc- cessful). Often we have a situation in which multiple categories make up the response. We may, for example, have subjects that are classified as positive, negative, and unde- termined for a given disease (a standard polytomous response). There may also be times when we have a response variable that is ordered. We may, for example, classify our subjects by BMI as underweight, ideal weight, overweight, or obese (an ordinal polyto- mous response). The modeling process is slightly more complex and requires the use of a computer program. For those interested in exploring these valuable methods further, we recommend the book by Hosmer and Lemeshow (1). Further Reading We have discussed only the basic concepts and applications of logistic regression. The technique has much wider application. Stepwise regression analysis may be used with logistic regression. There are also techniques available for574 CHAPTER 11 REGRESSION ANALYSIS: SOME ADDITIONAL TECHNIQUES constructing confidence intervals for odds ratios. The reader who wishes to learn more about logistic regression may consult the books by Hosmer and Lemeshow (1) and Kleinbaum (2). EXERCISES 11.4.1 In a study of violent victimization of women and men, Porcerelli et al. (A-11) collected informa- tion from 679 women and 345 men ages 18 to 64 years at several family-practice centers in the metropolitan Detroit area. Patients filled out a health history questionnaire that included a ques- tion about victimization. The following table shows the sample subjects cross-classified by gender and whether the subject self-identified as being “hit, kicked, punched, or otherwise hurt by some- one within the past year.” Subjects answering yes to that question are classified “violently victim- ized.” Use logistic regression analysis to find the regression coefficients and the estimate of the odds ratio. Write an interpretation of your results. Victimization No victimization Violently victimized Total WomenMenTotal 611 68 679308 37 345919 105 1024 Source: John H. Porcerelli, Rosemary Cogan, Patricia P. West, Edward A. Rose, Dawn Lambrecht, Karen E. Wilson, Richard K. Severson, and Dunia Karana, “Violent Victimization of Women and Men: Physical and Psychiatric Symptoms,” Journal of the American Board of Family Practice, 16 (2003), 32–39. 11.4.2 Refer to the research of Gallagher et al. (A-10) discussed in Example 11.4.2. Another covariate of interest was a score using the Hospital Anxiety and Depression Index. A higher value for this score indicates a higher level of anxiety and depression. Use the following data to predict whether a woman in the study participated in a cardiac rehabilitation program. Hospital Anxiety and Depression Index Scores for Nonparticipating Women 17 7 19 16 23 27 23 18 21 27 14 14 21 13 15 21 12 9 29 4 18 22 19 6 8 13 4 15 23 19 14 19 17 16 9 22 17 14 14 5 5 14 20 21 Hospital Anxiety and Depression Index Scores for Participating Women 23 3 24 13 26 19 25 15 22 13 21 25 6 29 22 11 12 20 18 24 18 8 (Continued)11.5 SUMMARY Hospital Anxiety and Depression Index Scores for Nonparticipating Women 25 19 23 6 8 15 30 18 10 29 8 12 27 12 9 16 6 22 10 95 27 16 11 19 23 22 25 11 20 11 28 12 19 18 13 12 7 12 1413 14 14 17 26 15 19 16 10 15 22 8 15 20 12 2 6 14 19 14 111319 575 Hospital Anxiety and Depression Index Scores for Participating Women 17 17 10 13 10 20 3 18 9 10 5 15 13 16 15 12 25 29 17 21 8 19 16 24 17 26 12 19 13 23 11 17 29 6 10 17 14 21 25 25 16 23 19 24 11 17 19 20 17 31 0 18 18 15 20 Source: Robyn Gallagher, R.N., Ph.D. Used with permission. 11.5 SUMMARY This chapter is included for the benefit of those who wish to extend their understand- ing of regression analysis and their ability to apply techniques to models that are more complex than those covered in Chapters 9 and 10. In this chapter we present some additional topics from regression analysis. We discuss the analysis that is appropri- ate when one or more of the independent variables is dichotomous. In this discussion the concept of dummy variable coding is presented. A second topic that we discuss is how to select the most useful independent variables when we have a long list of potential candidates. The technique we illustrate for the purpose is stepwise regres- sion analysis. Finally, we present the basic concepts and procedures that are involved in logistic regression analysis. We cover two situations: the case in which the inde- pendent variable is dichotomous, and the case in which the independent variable is continuous. Since the calculations involved in obtaining useful results from data that are appro- priate for analysis by means of the techniques presented in this chapter are complicated and time-consuming when attempted by hand, it is recommended that a computer be used to work the exercises.576 CHAPTER 11 REGRESSION ANALYSIS: SOME ADDITIONAL TECHNIQUES SUMMARY OF FORMULAS FOR CHAPTER 11 Formula Number NameFormula 11.4.1–11.4.3Representations of the simple linear regression model11.4.4Simple logistic regression modely = b0 + b1x + P my ƒ x = b 0 + b 1 x E 1y ƒx2 = b 0 + b 1 x 11.4.5Alternative representation of the simple logistic regression model ln c p d = b0 + b1x 1 - p p = exp1b 0 + b 1x2 1 + exp1b 0 + b 1x2 11.4.6Alternative representation of the multiple logistic regression model 11.4.7Alternative representation of the multiple logistic regression model Symbol Key• b 0 " regression intercept • b i " regression coefficient • P " regression model error term • E 1y ƒx2 " expected value of y at x p • ln c d " logit transformation 1 - p • my\|x " mean of y at x • xi " value of independent variable at i ln c p d = b 0 + b 1 x 1j + b 2x 2j + Á + b k x kj 1 - p p = exp1b 0 + b 1x 1j + b 2x 2j + Á + b k x kj2 1 + exp1b 0 + b 1x 1j + b 2x 2j + Á + b k x kj2 REVIEW QUESTIONS AND EXERCISES 1.What is a qualitative variable? 2.What is a dummy variable? 3.Explain and illustrate the technique of dummy variable coding. 4.Why is a knowledge of variable selection techniques important to the health sciences researcher? 5.What is stepwise regression? 6.Explain the basic concept involved in stepwise regression.REVIEW QUESTIONS AND EXERCISES 577 7.When is logistic regression used? 8.Write out and explain the components of the logistic regression model. 9.Define the word odds. 10.What is an odds ratio? 11.Give an example in your field in which logistic regression analysis would be appropriate when the independent variable is dichotomous. 12.Give an example in your field in which logistic regression analysis would be appropriate when the independent variable is continuous. 13.Find a published article in the health sciences field in which each of the following techniques is employed: (a) Dummy variable coding (b) Stepwise regression (c) Logistic regression Write a report on the article in which you identify the variables involved, the reason for the choice of the technique, and the conclusions that the authors reach on the basis of their analysis. 14. In Example 10.3.1, we saw that the purpose of a study by Jansen and Keller (A-12) was to pre- dict the capacity to direct attention (CDA) in elderly subjects. The study collected information on 71 community-dwelling older women with normal mental status. Higher CDA scores indicate bet- ter attentional functioning. In addition to the variables age and education level, the researchers per- formed stepwise regression with two additional variables: IADL, a measure of activities of daily living (higher values indicate greater number of daily activities), and ADS, a measure of atten- tional demands (higher values indicate more attentional demands). Perform stepwise regression with the data in the following table and report your final model, p values, and conclusions. CDAAgeEdyrsIADLADSCDAAgeEdyrs 4.57 -3.04 1.39 -3.55 -2.56 -4.66 -2.70 0.30 -4.46 -6.29 -4.43 0.18 -1.37 3.26 -1.12 -0.77 3.7372 68 65 85 84 90 79 74 69 87 84 79 71 76 73 86 6920 12 13 14 13 15 12 10 12 15 12 12 12 14 14 12 1728 27 24 27 28 27 28 24 28 21 27 28 28 29 29 26 2827 96 97 48 50 47 71 48 67 81 44 39 124 43 30 44 473.17 -1.19 0.99 -2.94 -2.21 -0.75 5.07 -5.86 5.00 0.63 2.62 1.77 -3.79 1.44 -5.77 -5.77 -4.6279 87 71 81 66 81 80 82 65 73 85 83 83 76 77 83 7912 12 14 16 16 16 13 12 13 16 16 17 8 20 12 12 14 IADL ADS 28 18 21 61 28 55 27 124 28 42 28 64 28 26 28 84 28 43 26 70 28 20 23 80 27 21 28 26 28 53 22 69 27 82 (Continued)578 CHAPTER 11 REGRESSION ANALYSIS: SOME ADDITIONAL TECHNIQUES CDAAgeEdyrsIADLADSCDAAgeEdyrsIADLADS -5.92 5.74 2.83 -2.40 -0.29 4.44 3.35 -3.13 -2.14 9.61 7.57 2.21 -2.30 1.73 6.03 -0.02 -7.65 4.1766 65 71 80 81 66 76 70 76 67 72 68 102 67 66 75 91 7411 16 14 18 11 14 17 12 12 12 20 18 12 12 14 18 13 1528 28 28 28 28 29 29 25 27 26 29 28 26 27 28 26 21 2849 48 46 25 27 54 26 100 38 84 44 52 18 80 54 67 101 90-2.03 -2.22 0.80 -0.75 -4.60 2.68 -3.69 4.85 -0.08 0.63 5.92 3.63 -7.07 6.39 -0.08 1.07 5.31 0.3069 66 75 77 78 83 85 76 75 70 79 75 94 76 84 79 78 7912 14 12 16 12 20 10 18 14 16 16 18 8 18 18 17 16 1228 28 28 27 22 28 20 28 29 28 27 28 24 28 27 27 28 2877 38 28 85 82 34 72 24 49 29 83 32 80 41 75 21 18 38 Source: Debra Jansen, Ph.D., R.N. Used with permission. 15. In the following table are the cardiac output (L/min) and oxygen consumption (VO2) values for a sample of adults (A) and children (C), who participated in a study designed to investigate the rela- tionship among these variables. Measurements were taken both at rest and during exercise. Treat cardiac output as the dependent variable and use dummy variable coding and analyze the data by regression techniques. Explain the results. Plot the original data and the fitted regression equations. Cardiac Output (L/min) 16. VO2 (L/min)Age GroupCardiac Output (L/min)VO2 (L/min)Age Group 4.0 7.5 3.0 8.9 5.1 5.8 9.1 3.5 7.2 5.1 6.0 5.7 14.2.21 .91 .22 .60 .59 .50 .99 .23 .51 .48 .74 .70 1.60A C C A C A A C A C C C A4.0 6.1 6.2 4.9 14.0 12.9 11.3 5.7 15.0 7.1 8.0 8.1 9.0.25 .22 .61 .45 1.55 1.11 1.45 .50 1.61 .83 .61 .82 1.15C A C C A A A C A C A A C 4.1.30C6.1.39A A simple random sample of normal subjects between the ages of 6 and 18 yielded the data on total body potassium (mEq) and total body water (liters) shown in the following table. Let totalREVIEW QUESTIONS AND EXERCISES 579 potassium be the dependent variable and use dummy variable coding to quantify the qualitative variable. Analyze the data using regression techniques. Explain the results. Plot the original data and the fitted regression equations. Total Body Potassium 795 1590 1250 1680 800 2100 1700 1260 1370 1000 1100 1500 1450 1100 17. Total Body WaterSex 13 16 15 21 10 26 15 16 18 11 14 20 19 14M F M M F M F M F F M F M M Total Body PotassiumTotal Body WaterSex 950 2400 1600 2400 1695 1510 2000 3200 1050 2600 3000 1900 220012 26 24 30 26 21 27 33 14 31 37 25 30F M F M F F F M F M M F F The data shown in the following table were collected as part of a study in which the subjects were preterm infants with low birth weights born in three different hospitals. Use dummy variable cod- ing and multiple regression techniques to analyze these data. May we conclude that the three sam- ple hospital populations differ with respect to mean birth weight when gestational age is taken into account? May we conclude that there is interaction between hospital of birth and gestational age? Plot the original data and the fitted regression equations. Birth Weight (kg) 1.4 .9 1.2 1.1 1.3 .8 1.0 .7 1.2 .8 1.5 1.3 1.4 1.5 1.0 1.8 Gestation Age (weeks)Hospital of BirthBirth Weight (kg)Gestation Age (weeks)Hospital of Birth 30 27 33 29 35 27 32 26 30 28 32 31 32 33 27 35A B A C A B A A C A B A C B A B1.0 1.4 .9 1.0 1.9 1.3 1.7 1.0 .9 1.0 1.6 1.6 1.7 1.6 1.2 1.529 33 28 28 36 29 35 30 28 31 31 33 34 35 28 30C C A C B B C A A A B B B C A B (Continued)580 CHAPTER 11 REGRESSION ANALYSIS: SOME ADDITIONAL TECHNIQUES Birth Weight (kg) Gestation Age (weeks)Hospital of BirthBirth Weight (kg)Gestation Age (weeks)Hospital of Birth 36 34 28 30C A B B1.8 1.5 1.2 1.234 34 30 32B C A C 1.4 1.2 1.1 1.2 18. Refer to Chapter 9, Review Exercise 18. In the study cited in that exercise, Maria Mathias (A-13) investigated the relationship between ages (AGE) of boys and improvement in measures of hyper- activity, attitude, and social behavior. In the study, subjects were randomly assigned to two differ- ent treatments. The control group (TREAT = 0) received standard therapy for hyperactivity, and the treatment group (TREAT = 1) received standard therapy plus pet therapy. The results are shown in the following table. Create a scatter plot with age as the independent variable and ATT (change in attitude with positive numbers indicating positive change in attitude) as the dependent variable. Use different symbols for the two different treatment groups. Use multiple regression techniques to determine whether age, treatment, or the interaction are useful in predicting ATT. Report your results. Subject 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 TREATAGEATTSubjectTREATAGEATT 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 09 9 13 6 9 8 8 9 7 12 9 10 12 9 12 9-1.2 0.0 -0.4 -0.4 1.0 0.8 -0.6 -1.2 0.0 0.4 -0.8 1.0 1.4 1.0 0.8 1.017 18 19 20 21 22 23 24 25 26 27 28 29 30 310 0 0 0 0 0 1 1 1 1 1 1 1 1 110 7 12 9 7 6 11 11 11 11 11 11 11 8 90.4 0.0 1.1 0.2 0.4 0.0 0.6 0.4 1.0 0.8 1.2 0.2 0.8 0.0 0.4 Source: Maria Mathias, M.D. and the Wright State University Statistical Consulting Center. Used with permission. For each study described in Exercises 19 through 21, answer as many of the following questions as possible: (a) Which is the dependent variable? (b) What are the independent variables? (c) What are the appropriate null and alternative hypotheses? (d) Which null hypotheses do you think were rejected? Why? (e) Which is the more relevant objective, prediction or estimation, or are the two equally relevant? Explain your answer.REVIEW QUESTIONS AND EXERCISES 581 (f) What is the sampled population? (g) What is the target population? (h) Which variables are related to which other variables? Are the relationships direct or inverse? (i) Write out the regression equation using appropriate numbers for parameter estimates. ( j) Give numerical values for any other statistics that you can. (k) Identify each variable as to whether it is quantitative or qualitative. (l) Explain the meaning of any statistics for which numerical values are given. 19. Golfinopoulos and Arhonditsis (A-14) used a multiple regression model in a study of tri- halomethanes (THMs) in drinking water in Athens, Greece. THMs are of concern since they have been related to cancer and reproductive outcomes. The researchers found the following regression model useful in predicting THM: THM = -.26chla + 1.57 pH + 28.74Br - 66.72Br 2 -43.63S + 1.13Sp + 2.62T \* S - .72T \* CL The variables were as follows: chla = chlorophyll concentration, pH = acid/base scale, Br = bromide concentration, S = dummy variable for summer, Sp = dummy variable for spring, T = temperature, and CL = chlorine concentration. The researchers reported R = .52, p 6 .001. 20. 21. In a study by Takata et al. (A-15), investigators evaluated the relationship between chewing ability and teeth number and measures of physical fitness in a sample of subjects ages 80 or higher in Japan. One of the outcome variables that measured physical fitness was leg extensor strength. To measure the ability to chew foods, subjects were asked about their ability to chew 15 foods (peanuts, vinegared octopus, and French bread, among others). Consideration of such variables as height, body weight, gender, systolic blood pressure, serum albumin, fasting glucose concentration, back pain, smoking, alcohol consumption, marital status, regular medical treatment, and regular exercise revealed that the number of chewable foods was significant in predicting leg extensor strength 1bN 1 = .075, p = .03662. However, in the presence of the other variables, number of teeth was not a significant predictor 1bN 1 = .003, p = .93732. Varela et al. (A-16) examined 515 patients who underwent lung resection for bronchogenic carci- noma. The outcome variable was the occurrence of cardiorespiratory morbidity after surgery. Any of the following postoperative events indicated morbidity: pulmonary atelectasis or pneumonia, respiratory or ventilatory insufficiency at discharge, need for mechanical ventilation at any time after extubation in the operating room, pulmonary thromboembolism, arrhythmia, myocardial ischemia or infarct, and clinical cardiac insufficiency. Performing a stepwise logistic regression, the researchers found that age 1p 6 .0012 and postoperative forced expiratory volume 1p = .0032 were statistically significant in predicting the occurrence of cardiorespiratory morbidity. For each of the data sets given in Exercises 22 through 29, do as many of the following as you think appropriate: (a) Apply one or more of the techniques discussed in this chapter. (b) Apply one or more of the techniques discussed in previous chapters. (c) Construct graphs. (d) Formulate relevant hypotheses, perform the appropriate tests, and find p values. (e) State the statistical decisions and clinical conclusions that the results of your hypothesis tests justify. (f) Describe the population(s) to which you think your inferences are applicable.582 CHAPTER 11 REGRESSION ANALYSIS: SOME ADDITIONAL TECHNIQUES 22. 23. A study by Davies et al. (A-17) was motivated by the fact that, in previous studies of contractile responses to b -adrenoceptor agonists in single myocytes from failing and nonfailing human hearts, they had observed an age-related decline in maximum response to isoproterenol, at frequencies where the maximum response to high Ca2 + in the same cell was unchanged. For the present study, the investigators computed the isoproterenol/Ca2 + ratio (ISO/CA) from measurements taken on myocytes from patients ranging in age from 7 to 70 years. Subjects were classified as older ( 750 years) and younger. The following are the (ISO/CA) values, age, and myocyte source of subjects in the study. Myocyte sources were reported as donor and biopsy. AgeISO/CAMyocyte Source 7 21 28 35 38 50 51 52 55 56 61 701.37 1.39 1.17 0.71 1.14 0.95 0.86 0.72 0.53 0.81 0.86 0.77Donor Donor Donor Donor Donor Donor Biopsy Biopsy Biopsy Biopsy Biopsy Biopsy Source: Dr. Sian E. Harding. Used with permission. Hayton et al. (A-18) investigated the pharmacokinetics and bioavailability of cefetamet and cefe- tamet pivoxil in infants between the ages of 3.5 and 17.3 months who had received the antibiotic during and after urological surgery. Among the pharmacokinetic data collected were the follow- ing measurements of the steady-state apparent volume of distribution (V). Also shown are previ- ously collected data on children ages 3 to 12 years (A-19) and adults (A-20). Weights (W) of subjects are also shown. Infants Children Adults W (kg)V (liters)W (kg)V (liters)W (kg)V (liters) 6.2 7.5 7.0 7.1 7.8 8.2 8.3 8.5 8.6 8.8 10.0 10.0 10.22.936 3.616 1.735 2.557 2.883 2.318 3.689 4.133 2.989 3.500 4.235 4.804 2.83313 14 14 15 16 17 17 17.5 17 17.5 20 23 254.72 5.23 5.85 4.17 5.01 5.81 7.03 6.62 4.98 6.45 7.73 7.67 9.8261 80 96 75 60 68 72.2 87 66.519.7 23.7 20.0 19.5 19.6 21.5 21.9 30.9 20.4 (Continued)REVIEW QUESTIONS AND EXERCISES Infants Children 583 Adults W (kg)V (liters)W (kg)V (liters) 10.3 10.6 10.7 10.8 11.0 12.5 13.14.068 3.640 4.067 8.366 4.614 3.168 4.15837 28 47 29 3714.40 10.90 15.40 9.86 14.40 W (kg) V (liters) Source: Dr. Klaus Stoeckel. Used with permission. 24. According to Fils-Aime et al. (A-21), epidemiologic surveys have found that alcoholism is the most common mental or substance abuse disorder among men in the United States. Fils-Aime and asso- ciates investigated the interrelationships of age at onset of excessive alcohol consumption, family his- tory of alcoholism, psychiatric comorbidity, and cerebrospinal fluid (CSF) monoamine metabolite concentrations in abstinent, treatment-seeking alcoholics. Subjects were mostly white males classi- fied as experiencing early (25 years or younger) or late (older than 25 years) onset of excessive alco- hol consumption. Among the data collected were the following measurements on CSF tryptophan (TRYPT) and 5-hydroxyindoleacetic acid (5-HIAA) concentrations (pmol/ml). 5-HIAATRYPTOnset 1 " Early 0 " Late 57 116 81 78 206 64 123 147 102 93 128 69 20 66 90 103 68 81 143 121 149 823315 2599 3334 2505 3269 3543 3374 2345 2855 2972 3904 2564 8832 4894 6017 3143 3729 3150 3955 4288 3404 25471 0 1 0 0 1 0 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1 5-HIAATRYPT 102 51 92 104 50 93 146 96 112 23 109 80 111 85 131 58 110 80 42 80 91 1023181 2513 2764 3098 2900 4125 6081 2972 3962 4894 3543 2622 3012 2685 3059 3946 3356 3671 4155 1923 3589 3839 Onset 1 " Early 0 " Late 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 0 (Continued)584 CHAPTER 11 REGRESSION ANALYSIS: SOME ADDITIONAL TECHNIQUES 5-HIAATRYPTOnset 1 " Early 0 " Late 100 117 41 223 96 87 96 34 98 86 118 84 99 114 140 74 45 51 99 54 93 50 118 96 49 133 105 61 197 87 50 109 59 107 85 156 110 81 53 64 57 29 343633 3309 3315 3418 2295 3232 3496 2656 4318 3510 3613 3117 3496 4612 3051 3067 2782 5034 2564 4335 2596 2960 3916 2797 3699 2394 2495 2496 2123 3320 3117 3308 3280 3151 3955 3126 2913 3786 3616 3277 2656 4953 43401 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 0 1 1 0 0 0 1 1 1 1 0 1 Source: Dr. Markku Linnoila. Used with permission. 5-HIAATRYPTOnset 1 " Early 0 " Late 93 98 78 152 108 102 122 81 81 99 73 163 109 90 110 48 77 67 92 86 101 88 38 75 35 53 77 179 151 57 45 76 46 98 84 119 41 40 149 116 76 962627 3181 4428 3303 5386 3282 2754 4321 3386 3344 3789 2131 3030 4731 4581 3292 4494 3453 3373 3787 3842 2882 2949 2248 3203 3248 3455 4521 3240 3905 3642 5233 4150 2579 3249 3381 4020 4569 3781 2346 3901 38220 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1REVIEW QUESTIONS AND EXERCISES 25. 585 The objective of a study by Abrahamsson et al. (A-22) was to investigate the anti-thrombotic effects of an inhibitor of the plasminogen activator inhibitor-1 (PAI-1) in rats given endotoxin. Experi- mental subjects were male Sprague–Dawley rats weighing between 300 and 400 grams. Among the data collected were the following measurements on PAI-1 activity and the lung 125I-concen- tration in anesthetized rats given three drugs: Drugs Plasma PAI-1 Activity (U/ml) 125 I-Fibrin in the Lungs (% of Ref. Sample) Endotoxin127 175 161 137 219 260 203 195 414 244158 154 118 77 172 277 216 169 272 192 Endotoxin + PRAP-1 low dose107 103 248 164 176 230 184 276 201 15849 28 187 109 96 126 148 17 97 86 Endotoxin + PRAP-1 high dose132 130 75 140 166 194 121 111 208 21186 24 17 41 114 110 26 53 71 90 Source: Dr. Tommy Abrahamsson. Used with permission. 26. Pearse and Sylvester (A-23) conducted a study to determine the separate contributions of ischemia and extracorporeal perfusion to vascular injury occurring in isolated sheep lungs and to determine the oxygen dependence of this injury. Lungs were subjected to ischemia alone, extracorporeal perfusion alone, and both ischemia and extracorporeal perfusion. Among the data collected were the following observations on change in pulmonary arterial pressure (mm Hg) and pulmonary vascular permeability assessed by estimation of the reflection coefficient for albumin in perfused lungs with and without preceding ischemia:586 CHAPTER 11 REGRESSION ANALYSIS: SOME ADDITIONAL TECHNIQUES Ischemic–Perfused Lungs Change in Pulmonary Pressure 8.0 3.0 10.0 23.0 15.0 43.0 18.0 27.0 13.0 0.0 Reflection Coefficient 0.220 0.560 0.550 0.806 0.472 0.759 0.489 0.546 0.548 0.467 Perfused Lungs Change in Pulmonary PressureReflection Coefficient 34.0 31.0 4.0 48.0 32.0 27.0 25.0 25.00.693 0.470 0.651 0.999 0.719 0.902 0.736 0.718 Source: Dr. David B. Pearse. Used with permission. 27. The purpose of a study by Balzamo et al. (A-24) was to investigate, in anesthetized rabbits, the effects of mechanical ventilation on the concentration of substance P (SP) measured by radioim- munoassay in nerves and muscles associated with ventilation and participating in the sensory inner- vation of the respiratory apparatus and heart. SP is a neurotransmitter located in primary sensory neurons in the central and autonomic nervous systems. Among the data collected were the follow- ing measures of SP concentration in cervical vagus nerves (X) and corresponding nodose ganglia (NG), right and left sides: SPXrightSPNGrightSPXleftSPNGleft 0.6500 2.5600 1.1300 1.5500 35.9000 19.0000 13.6000 8.0000 7.4000 3.3000 19.8000 8.5000 5.4000 11.9000 47.7000 14.2000 2.9000 6.60009.6300 3.7800 7.3900 3.2800 22.0000 22.8000 2.3000 15.8000 1.6000 11.6000 18.0000 6.2000 7.8000 16.9000 35.9000 10.2000 1.6000 3.70003.3000 0.6200 0.9600 2.7000 4.5000 8.6000 7.0000 4.1000 5.5000 9.7000 13.8000 11.0000 11.9000 8.2000 3.9000 3.2000 2.7000 2.80001.9300 2.8700 1.3100 5.6400 9.1000 8.0000 8.3000 4.7000 2.5000 8.0000 8.0000 17.2000 5.3000 10.6000 3.3000 1.9000 3.5000 2.5000 3.70001.3000 Source: Dr. Yves Jammes. Used with permission.REVIEW QUESTIONS AND EXERCISES 28. 587 Scheeringa and Zeanah (A-25) examined the presence of posttraumatic stress disorder (PTSD), the severity of posttraumatic symptomatology, and the pattern of expression of symptom clusters in relation to six independent variables that may be salient to the development of a posttraumatic dis- order in children under 48 months of age. The following data were collected during the course of the study. Predictor Variables Response Variables GenderAgeAcute/ Rept.InjuryWit./ Exper.Threat to CaregiverReexpNumbArous 0 0 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1 1 1 0 0 0 01 1 1 1 0 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 00 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 11 0 0 0 1 1 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 01 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 01 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 13 2 3 3 1 3 4 5 2 4 1 1 0 4 3 3 3 5 1 4 2 1 4 3 3 3 2 2 2 2 1 3 2 1 2 3 30 2 1 1 3 1 2 2 1 1 3 3 3 1 2 1 1 2 2 4 1 1 1 2 1 1 2 0 0 3 2 2 4 1 3 1 10 1 1 0 1 0 0 0 3 0 0 0 0 2 1 2 2 1 2 0 2 2 1 1 2 2 0 3 1 1 1 0 2 0 2 4 2 FrAgg 1 1 1 4 1 1 1 4 2 0 1 2 0 1 3 1 2 1 2 3 3 1 1 0 4 4 0 0 2 3 1 4 0 2 3 3 3 (Continued)588 CHAPTER 11 REGRESSION ANALYSIS: SOME ADDITIONAL TECHNIQUES Predictor Variables Response Variables GenderAgeAcute/ Rept.InjuryWit./ Exper.Threat to CaregiverReexpNumbArousFrAgg 0 1 10 0 00 0 00 0 11 0 10 1 01 4 41 3 20 2 30 3 2 0011101221 0 = male 1 = female Age 0 = younger than 18 months at time of trauma 1 = older than 18 months Acute/rept. 0 = trauma was acute, single blow 1 = trauma was repeated or chronic Injury 0 = subject was not injured in the trauma 1 = subject was physically injured in the trauma Wit./exper. 0 = subject witnessed but did not directly experience trauma 1 = subject directly experienced the trauma Threat to caregiver 0 = caregiver was not threatened in the trauma 1 = caregiver was threatened in the trauma Reexp " Reexperiencing cluster symptom count Numb " Numbing of responsiveness/avoidance cluster symptom count Arous " Hyperarousal cluster symptom count FrAgg " New fears/aggression cluster symptom count Source: Dr. Michael S. Scheeringa. Used with permission. Key: Gender 29. Age (years) 67 62 68 61 70 71 60 57 One of the objectives of a study by Mulloy and McNicholas (A-26) was to compare ventila- tion and gas exchange during sleep and exercise in chronic obstructive pulmonary disease (COPD). The investigators wished also to determine whether exercise studies could aid in the prediction of nocturnal desaturation in COPD. Subjects (13 male, 6 female) were ambulatory patients attending an outpatient respiratory clinic. The mean age of the patients, all of whom had severe, stable COPD, was 64.8 years with a standard deviation of 5.2. Among the data col- lected were measurements on the following variables: BMIPa O2 (mm Hg)Pa CO2 (mm Hg)FEV1 (% Predicted)Lowest Ex. SaO2aMean Sleep SaO2aLowest Sleep SaO2a 23.46 25.31 23.11 25.15 24.54 25.47 19.49 21.3752.5 57.75 72 72 78 63.75 80.25 84.7554 49.575 43.8 47.4 40.05 45.375 42.15 40.222 19 41 38 40 31 28 2074 82 95 88 88 85 91 9170.6 85.49 88.72 91.11 92.86 88.95 94.78 93.7256 76 82 76 92 80 90 89 Fall Sleep SaO2a 29.6 11.66 11.1 18.45 0.8 13 4 5.8 (Continued)Age (years) 69 57 74 63 64 73 63 62 67 57 66 REVIEW QUESTIONS AND EXERCISES589 BMIPa O2 (mm Hg)Pa CO2 (mm Hg)FEV1 (% Predicted)Lowest Ex. SaO2aMean Sleep SaO2aLowest Sleep SaO2aFall Sleep SaO2a 25.78 22.13 26.74 19.07 19.61 30.30 26.12 21.71 24.75 25.98 32.0068.25 83.25 57.75 78 90.75 69.75 51.75 72 84.75 84.75 51.7543.8 43.725 51 44.175 40.35 38.85 46.8 41.1 40.575 40.05 53.17532 20 33 36 27 53 39 27 45 35 3085 88 75 81 90 87 67 88 87 94 8390.91 94.39 89.89 93.95 95.07 90 69.31 87.95 92.95 93.4 80.1779 86 80 82 92 76 46 72 90 86 7113 9.5 14.11 13 4 18 34.9 22 2.17 8.45 16 a Treated as dependent variable in the authors’ analyses. BMI = body mass index; Pa O2 = arterial oxygen tension; Pa CO2 = arterial carbon dioxide pressure; FEV1 = forced expiratory volume in 1 second; SaO2 = arterial oxygen saturation. Source: Dr. Eithne Mulloy. Used with permission. Exercises for Use with the Large Data Sets Available on the Following Website: www.wiley.com/college/daniel 1. The goal of a study by Gyurcsik et al. (A-27) was to examine the usefulness of aquatic exercise- related goals, task self-efficacy, and scheduling self-efficacy for predicting aquatic exercise atten- dance by individuals with arthritis. The researchers collected data on 142 subjects participating in Arthritis Foundation Aquatics Programs. The outcome variable was the percentage of sessions attended over an 8-week period (ATTEND). The following predictor variables are all centered val- ues. Thus, for each participant, the mean for all participants is subtracted from the individual score. The variables are: GOALDIFF—higher values indicate setting goals of higher participation. GOALSPEC—higher values indicate higher specificity of goals related to aquatic exercise. INTER—interaction of GOALDIFF and GOALSPEC. TSE—higher values indicate participants’ confidence in their abilities to attend aquatic classes. SSE—higher values indicate participants’ confidence in their abilities to perform eight tasks related to scheduling exercise into their daily routine for 8 weeks. MONTHS—months of participation in aquatic exercise prior to start of study. With the data set AQUATICS, perform a multiple regression to predict ATTEND with each of the above variables. What is the multiple correlation coefficient? What variables are significant in pre- dicting ATTEND? What are your conclusions? 2. Rodehorst (A-28) conducted a prospective study of 212 rural elementary school teachers. The main outcome variable was the teachers’ intent to manage children demonstrating symptoms of asthma in their classrooms. This variable was measured with a single-item question that used a seven-point Likert scale (INTENT, with possible responses of 1 = extremely probable to590 CHAPTER 11 REGRESSION ANALYSIS: SOME ADDITIONAL TECHNIQUES 7 = extremely improbable). Rodehorst used the following variables as independent variables to predict INTENT: SS = Social Support. Scores range from 7 to 49, with higher scores indicating higher perceived social support for managing children with asthma in a school setting. ATT = Attitude. Scores range from 15 to 90, with higher scores indicating more favorable attitudes toward asthma. KNOW = Knowledge. Scores range from 0 to 24, with higher scores indicating higher general knowledge about asthma. CHILD = Number of children with asthma the teacher has had in his or her class during his or her entire teaching career. SE = Self-efficacy. Scores range from 12 to 60, with higher scores indicating higher self-efficacy for managing children with asthma in the school setting. YRS = Years of teaching experience. With the data TEACHERS, use stepwise regression analysis to select the most useful variables to include in a model for predicting INTENT. 3. Refer to the weight loss data on 588 cancer patients and 600 healthy controls (WGTLOSS). Weight loss among cancer patients is a well-known phenomenon. Of interest to clinicians is the role played in the process by metabolic abnormalities. One investigation into the relationships among these variables yielded data on whole-body protein turnover (Y ) and percentage of ideal body weight for height (X ). Subjects were lung cancer patients and healthy controls of the same age. Select a simple random sample of size 15 from each group and do the following: (a) Draw a scatter diagram of the sample data using different symbols for each of the two groups. (b) Use dummy variable coding to analyze these data. (c) Plot the two regression lines on the scatter diagram. May one conclude that the two sampled populations differ with respect to mean protein turnover when percentage of ideal weight is taken into account? May one conclude that there is interaction between health status and percentage of ideal body weight? Prepare a verbal interpretation of the results of your analysis and compare your results with those of your classmates. REFERENCES Methodology References 1. DAVID W. HOSMER and STANLEY LEMESHOW, Applied Logistic Regression, 2nd ed. Wiley, New York, 2000. 2. DAVID G. KLEINBAUM, Logistic Regression: A Self-Learning Text, New York, Springer, 1994. Applications References A-1. North Carolina State Center for Health Statistics and Howard W. Odum Institute for Research in Social Sci- ence at the University of North Carolina at Chapel Hill, Birth Data set for 2001 found at www.irss.unc.edu/ ncvital/bfd1down.html. All sampling and coding performed by John Holcomb and do not represent the find- ings of the Center or Institute. A-2. B. BOLWELL, R. SOBECKS, B. POHLMAN, S. ANDRESEN, K. THEIL, S. SERAFINO, L. RYBICKI, and M. KALAYCIO, “Etoposide (VP-16) Plus G-CSF Mobilizes Different Dendritic Cell Subsets than Does G-CSF Alone,” Bone Marrow Transplantation, 31 (2003), 95–98.REFERENCES 591 A-3. MANOJ PANDEY, LAL B. SHARMA, and VIJAY K. SHUKLA, “Cytochrome P-450 Expression and Lipid Per- oxidation in Gallbladder Cancer,” Journal of Surgical Oncology, 82 (2003), 180–183. A-4. MORI J. KRANTZ, ILANA B. KUTINSKY, ALASTAIR D. ROBERTSON, and PHILIP S. MEHLER, “Dose-Related Effects of Methadone on QT Prolongation in a Series of Patients with Torsade de Pointes,” Pharmacotherapy, 23 (2003), 802–805. A-5. ROBERT A. REISS, CURTIS E. HAAS, DEBORAH L. GRIFFIS, BERNADETTE PORTER, and MARY ANN TARA, “Point-of-Care versus Laboratory Monitoring of Patients Receiving Different Anticoagulant Therapies,” Pharmacotherapy 22, (2002), 677–685. A-6. GWI-RYUNG SON, MAY L. WYKLE, and JACLENE A. ZAUSZNIEWSKI, “Korean Adult Child Caregivers of Older Adults with Dementia,” Journal of Gerontological Nursing, 29 (2003), 19–28. A-7. M. NAEIJE, “Local Kinematic and Anthropometric Factors Related to the Maximum Mouth Opening in Healthy Individuals,” Journal of Oral Rehabilitation, 29 (2002), 534–539. A-8. DANIEL F. CONNOR, RONALD J. STEINGARD, JENNIFER J. ANDERSON, and RICHARD H. MELLONI, “Gender Dif- ferences in Reactive and Proactive Aggression,” Child Psychiatry and Human Development, 33 (2003), 279–294. A-9. DANIEL H. LAMONT, MATTHEW J. BUDOFF, DAVID M. SHAVELLE, ROBERT SHAVELLE, BRUCE H. BRUNDAGE, and JAMES M. HAGAR, “Coronary Calcium Scanning Adds Incremental Value to Patients with Positive Stress Tests,” American Heart Journal, 143 (2002), 861–867. A-10. ROBYN GALLAGHER, SHARON MCKINLEY, and KATHLEEN DRACUP, “Predictors of Women’s Attendance at Car- diac Rehabilitation Programs,” Progress in Cardiovascular Nursing, 18 (2003), 121–126. A-11. JOHN H. PORCERELLI, ROSEMARY COGAN, PATRICIA P. WEST, EDWARD A. ROSE, DAWN LAMBRECHT, KAREN E. WILSON, RICHARD K. SEVERSON, and DUNIA KARANA, “Violent Victimization of Women and Men: Physical and Psychiatric Symptoms,” Journal of the American Board of Family Practice, 16 (2003), 32–39. A-12. DEBRA A. JANSEN and MARY L. KELLER, “Cognitive Function in Community-Dwelling Elderly Women,” Journal of Gerontological Nursing, 29 (2003), 34–43. A-13. MARIA MATHIAS and the Wright State University Statistical Consulting Center. A-14. SPYROS K. GOLFINOPOULOS and GEORGE B. ARHONDITSIS, “Multiple Regression Models: A Methodology for Evaluating Trihalomethane Concentrations in Drinking Water from Raw Water Characteristics,” Chemosphere, 47 (2002), 1007–1018. A-15. Y. TAKATA, T. ANSAI, S. AWANO, T. HAMASAKI, Y. YOSHITAKE, Y. KIMURA, K. SONOKI, M. WAKISAKA, M. FUKUHARA, and T. TAKEHARA, “Relationship of Physical Fitness to Chewing in an 80-Year-Old Population,” Oral Diseases, 10 (2004), 44–49. A-16. G. VARELA, N. NOVOA, M. F. JIMÉNEZ, and G. SANTOS, “Applicability of Logistic Regression (LR) Risk Mod- eling to Decision Making in Lung Cancer Resection,” Interactive Cardiovascular and Thoracic Surgery, 2 (2003), 12–15. A-17. C. H. DAVIES, N. FERRARA, and S. E. HARDING, “ b -Adrenoceptor Function Changes with Age of Subject in Myocytes from Non-Failing Human Ventricle,” Cardiovascular Research, 31 (1996), 152–156. A-18. WILLIAM L. HAYTON, JOHANNES KNEER, RONALD DE GROOT, and KLAUS STOECKEL, “Influence of Matura- tion and Growth on Cefetamet Pivoxil Pharmacokinetics: Rational Dosing for Infants,” Antimicrobial Agents and Chemotherapy, 40 (1996), 567–574. A-19. W. L. HAYTON, R. A. WALSTAD, E. THURMANN-NIELSEN, T. KUFAAS, J. KNEER, R. J. AMBROS, H. E. RUGSTAD, E. MONN, E. BODD, and K. STOECKEL,“Pharmacokinetics of Intravenous Cefetamet and Oral Cefetamet Pivoxil in Children,” Antimicrobial Agents and Chemotherapy, 35 (1991), 720–725. Erratum, 36 (1992), 2575. A-20. M. P. DUCHARME, D. J. EDWARDS, P. J. MCNAMARA, and K. STOECKEL, “Bioavailability of Syrup and Tablet Formulations of Cefetamet Pivoxil,” Antimicrobial Agents and Chemotherapy, 37 (1993), 2706 –2709. A-21. MARIE-LOURDES FILS-AIME, MICHAEL J. ECKARDT, DAVID T. GEORGE, GERALD L. BROWN, IVAN MEFFORD, and MARKKU LINNOILA, “Early-Onset Alcoholics Have Lower Cerebrospinal Fluid 5-Hydroxyindoleacetic Acid Levels than Late-Onset Alcoholics,” Archives of General Psychiatry, 53 (1996), 211–216. A-22. T. ABRAHAMSSON, V. NERME, M. STRÖMQVIST, B. ÅKERBLOM, A. LEGNEHED, K. PETTERSSON, and A. WESTIN ERIKSSON, “Anti-thrombotic Effect of PAI-1 Inhibitor in Rats Given Endotoxin,” Thrombosis and Haemosta- sis, 75 (1996), 118–126. A-23. DAVID B. PEARSE and J. T. SYLVESTER, “Vascular Injury in Isolated Sheep Lungs: Role of Ischemia, Extracor- poreal Perfusion, and Oxygen,” American Journal of Respiratory and Critical Care Medicine, 153 (1996), 196–202.592 CHAPTER 11 REGRESSION ANALYSIS: SOME ADDITIONAL TECHNIQUES A-24. EMMANUEL BALZAMO, PIERRE JOANNY, JEAN GUILLAUME STEINBERG, CHARLES OLIVER, and YVES JAMMES, “Mechanical Ventilation Increases Substance P Concentration in the Vagus, Sympathetic, and Phrenic Nerves,” American Journal of Respiratory and Critical Care Medicine, 153 (1996), 153–157. A-25. MICHAEL S. SCHEERINGA and CHARLES H. ZEANAH, “Symptom Expression and Trauma Variables in Children Under 48 Months of Age,” Infant Mental Health Journal, 16 (1995), 259–270. A-26. EITHNE MULLOY and WALTER T. MCNICHOLAS, “Ventilation and Gas Exchange During Sleep and Exercise in Severe COPD,” Chest, 109 (1996), 387–394. A-27. NANCY C. GYURCSIK, PAUL A. ESTABROOKS, and MELISSA J. FRAHM-TEMPLAR, “Exercise-Related Goals and Self-Efficacy as Correlates of Aquatic Exercise in Individuals with Arthritis,” Arthritis Care and Research, 49 (2003), 306–313. A-28. T. KIM RODEHORST, “Rural Elementary School Teachers’ Intent to Manage Children with Asthma Symptoms,” Pediatric Nursing, 29 (2003), 184–194.12 CHAPTER THE CHI-SQUARE DISTRIBUTION AND THE ANALYSIS OF FREQUENCIES CHAPTER OVERVIEW This chapter explores techniques that are commonly used in the analysis of count or frequency data. Uses of the chi-square distribution, which was mentioned briefly in Chapter 6, are discussed and illustrated in greater de- tail. Additionally, statistical techniques often used in epidemiological studies are introduced and demonstrated by means of examples. TO P I C S 12.1INTRODUCTION 12.2THE MATHEMATICAL PROPERTIES OF THE CHI-SQUARE DISTRIBUTION 12.3TESTS OF GOODNESS-OF-FIT 12.4TESTS OF INDEPENDENCE 12.5TESTS OF HOMOGENEITY 12.6THE FISHER EXACT TEST 12.7RELATIVE RISK, ODDS RATIO, AND THE MANTEL-HAENSZEL STATISTIC 12.8SURVIVAL ANALYSIS 12.9SUMMARY LEARNING OUTCOMES After studying this chapter, the student will 1. understand the mathematical properties of the chi-square distribution. 2. be able to use the chi-square distribution for goodness-of-fit tests. 3. be able to construct and use contingency tables to test independence and homogeneity. 4. be able to apply Fisher’s exact test for 2 ( 2 tables. 5. understand how to calculate and interpret the epidemiological concepts of relative risk, odds ratios, and the Mantel-Haenszel statistic. 593594 12.1 CHAPTER 12 THE CHI-SQUARE DISTRIBUTION AND THE ANALYSIS OF FREQUENCIES INTRODUCTION In the chapters on estimation and hypothesis testing, brief mention is made of the chi-
